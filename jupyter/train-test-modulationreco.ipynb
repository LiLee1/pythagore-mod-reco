{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the networks for modulation recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Helion du Mas des Bourboux <helion.dumasdesbourboux'at'thalesgroup.com>\n",
    "#         Thomas Courtat <thomas.courtat'at'thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2021 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import mkdir\n",
    "from os.path import exists as path_exists\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "print(f'Tensorflow version {tensorflow.__version__}')\n",
    "print(f'Available devices:\\n{[x.name for x in device_lib.list_local_devices()]}')\n",
    "\n",
    "\n",
    "from pythagore_modreco.data import read_augmod, read_RML2016, read_RML2018\n",
    "from pythagore_modreco.utils import TimeHistory,split_dataset\n",
    "from pythagore_modreco import neural_nets_keras\n",
    "\n",
    "\n",
    "np.random.seed(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the folder where your dataset(s) is/are\n",
    "data_path = \"/media/ml4radio/modulationrecopublic/data/\"\n",
    "\n",
    "# Please specify a folder to log information during model training \n",
    "log_path = \"/home/helion/xp/log_modreco/tests/\"\n",
    "\n",
    "if not path_exists(log_path):\n",
    "    mkdir(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Please chose a dataset name from:\n",
    "# AugMod\n",
    "# RadioML2016.04c\n",
    "# RadioML2016.10a\n",
    "# RadioML2016.10b\n",
    "# RadioML2018.01a\n",
    "dataset_name = \"AugMod\"\n",
    "\n",
    "# Please choose signal duration in seconds. \n",
    "# Beware, that duration should be less or equal to the chosen dataset signal lengths\n",
    "# Set to None if you want to take as much as there is in the dataset\n",
    "signal_duration = 128\n",
    "\n",
    "# Please choose a cut in SNR\n",
    "# The resulting dataset will consit in all data>=snr_cut\n",
    "# set to None if no cut\n",
    "snr_cut = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the selected dataset ; \n",
    "\n",
    "This cell outputs: \n",
    "- signals : a numpy array containing signal data \n",
    "- class_onehot : a numpy array containing one hot encoded labels associated to data \n",
    "- snrs: an array associating snr to each signal \n",
    "- class_list: a list of strings associating the modulation / signal kind name to the indexes of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"AugMod\":\n",
    "    \n",
    "    fName = join(data_path,'augmod.hdf5')\n",
    "    data_dict = read_augmod(fName)\n",
    "    \n",
    "    signals  = data_dict['signals']\n",
    "    class_idx = data_dict['modulations']\n",
    "    snrs = data_dict['snr']\n",
    "    \n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    class_list = data_dict['classes']\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.04c\":\n",
    "\n",
    "    fName = join(data_path,'2016.04C.multisnr.pkl')\n",
    "    \n",
    "    signals, class_idx, snrs, class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.10a\":\n",
    "\n",
    "    fName = join(data_path,'RML2016.10a_dict.pkl')\n",
    "    \n",
    "    signals, class_idx, snrs,class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.10b\":\n",
    "\n",
    "    fName = join(data_path,'RML2016.10b.dat')\n",
    "    \n",
    "    signals, class_idx, snrs,class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2018.01a\":\n",
    "\n",
    "    fName = join(data_path,'GOLD_XYZ_OSC.0001_1024.hdf5')\n",
    "    \n",
    "    signals, class_onehot, snrs ,class_list = read_RML2018(fName)\n",
    "    #snrs = snrs.reshape(-1)\n",
    "    class_idx = np.argmax(class_onehot,axis=-1)\n",
    "else: \n",
    "    print('Data not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs_list = sorted( list( set( snrs ) ) )\n",
    "print(f'{dataset_name} loaded, {signals.shape[0]} signal with shape {signals.shape[1:]}' )\n",
    "print(f'List of signal SNR: {snrs_list}')\n",
    "print(f'List of modulations under consideration: {class_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposes the data so the real/imag axis is the last as expected by deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial data shape: {signals.shape}')\n",
    "signals = signals.transpose((0,2,1))\n",
    "print(f'Transposed data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trunk signal to `signal_duration`samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not signal_duration is None:\n",
    "    print(f'Initial data shape: {signals.shape}')\n",
    "    signals = signals[:,:signal_duration,:]\n",
    "    print(f'Trunked data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters signal by snr if requested above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not snr_cut is None:\n",
    "    print(f'Initial data shape: {signals.shape}')\n",
    "    w = snrs>=snr_cut\n",
    "    signals = signals[w]\n",
    "    class_idx = class_idx[w]\n",
    "    snrs = snrs[w]\n",
    "    class_onehot = class_onehot[w]\n",
    "    print(f'New data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the power of each signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize the power of each signal\n",
    "norm = np.sqrt(np.mean(signals**2,axis=(1,2),keepdims=True))\n",
    "signals/=norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into train and test sets. Also shuffles data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_idx ,_,_,_, X_test,y_test,test_idx= split_dataset(signals, \n",
    "    class_onehot, \n",
    "    p_train=0.5,p_test=0.5)\n",
    "\n",
    "SNR_train = snrs[train_idx]\n",
    "SNR_test = snrs[test_idx]\n",
    "\n",
    "print(f'Train dataset shape: {X_train.shape}')\n",
    "print(f'Test dataset shape: {X_test.shape} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_test  shape: {X_test.shape}, y_test  shape: {y_test.shape}')\n",
    "\n",
    "input_shp = list(X_train.shape[1:])\n",
    "output_shp = y_train.shape[1]\n",
    "\n",
    "print(f'Network input shape in variable input-shp: {input_shp}')\n",
    "print(f'Network output shape in variable input-shp: {output_shp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_to_tensor(X_train)\n",
    "y_train = convert_to_tensor(y_train)\n",
    "X_test = convert_to_tensor(X_test)\n",
    "y_test = convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning model training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to instanciate and train a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,name_network): \n",
    "    \n",
    "    clear_session()\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=nb_epoch, batch_size=batch_size,\n",
    "                        validation_data =( X_test , y_test ), \n",
    "                        verbose=1,\n",
    "                        callbacks=[time_callback])\n",
    "\n",
    "    model.save(join(log_path,'model-{}-{}-trained{}.h5'.format(dataset_name,name_network,signal_duration)))\n",
    "\n",
    "    data = np.array(list(zip(history.epoch, history.history['val_accuracy'], history.history['accuracy'])))\n",
    "    np.savetxt(join(log_path,'history-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)),data)\n",
    "\n",
    "    data = np.array(list(zip(history.epoch, time_callback.times)))\n",
    "    np.savetxt(join(log_path,'history_time-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)),data)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LModCNN (ours)\n",
    "\n",
    "Generate LModCNN architecture as defined in Courtat and du Mas des Bourboux, <i>A light neural network for modulation detection under impairments</i>, ISNCC 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_network = \"LModCNN\"\n",
    "\n",
    "dynamic_input_shp = input_shp.copy()\n",
    "dynamic_input_shp[0] = None\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(dynamic_input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LModCNNResNet Relu (ours)\n",
    "\n",
    "Generate LModCNN with residual connexion architecture as defined in Courtat and du Mas des Bourboux, <i>A light neural network for modulation detection under impairments</i>, ISNCC 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_network = \"LModCNNResNetRelu\"\n",
    "\n",
    "dynamic_input_shp = input_shp.copy()\n",
    "dynamic_input_shp[0] = None\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(dynamic_input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLConvNet\n",
    "\n",
    "Generate RMLConvNet as defined in O'Shea et Al., <i>Convolutional radio modulation recognition networks</i>, 2016\n",
    "The implementation is an adaptation of\n",
    "https://github.com/radioML/examples/blob/master/modulation_recognition/RML2016.10a_VTCNN2_example.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_network = \"RMLConvNet\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLCNNVGG\n",
    "\n",
    "Generate RML CNN/VGG  as defined in O'Shea et Al., <i>Over-the-Air Deep Learning Based Radio Signal Classification</i>,  2018. The implementation is an adaptation of https://github.com/leena201818/radioml/blob/master/rmlmodels/VGGLikeModel.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_network = \"RMLCNNVGG\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLResNet\n",
    "Generate RML Residual Network  as defined in O'Shea et Al., <i> Over-the-Air Deep Learning Based Radio Signal Classification</i>,  2018. \n",
    "The implementation is an adaptation of https://github.com/liuzhejun/ResNet-for-Radio-Recognition/blob/master/ResNet_Model.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_network = \"RMLResNet\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_name_to_legend = {\n",
    "    'RMLConvNet':'RML-ConvNet',\n",
    "    'RMLCNNVGG':'RML-CNN/VGG',\n",
    "    'RMLResNet':'RML-ResNet',\n",
    "    'LModCNN':'Mod-LCNN (ours)',\n",
    "    'LModCNNResNetRelu':'Mod-LRCNN (ours)',\n",
    "}\n",
    "\n",
    "networks_to_plot = ['RMLConvNet','RMLCNNVGG','RMLResNet','LModCNN','LModCNNResNetRelu' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training trajectories\n",
    "\n",
    "Plots the evolution of error through learning epochs both for train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for name_network in networks_to_plot:\n",
    "\n",
    "    data = np.loadtxt(join(log_path,'history-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)))\n",
    "\n",
    "    p = plt.plot(data[:,0], 1.-data[:,1],\n",
    "        label=from_name_to_legend[name_network],linewidth=2)\n",
    "    plt.plot(data[:,0], 1.-data[:,2],':',\n",
    "        linewidth=2,color=p[0].get_color(),alpha=0.8)\n",
    "\n",
    "plt.plot(data[:,0] ,1.-1./output_shp*np.ones_like(data[:,0]),\n",
    "    '--',label='Random classifier',linewidth=2,color='black')\n",
    "\n",
    "plt.legend(ncol=2,loc=1)\n",
    "plt.grid()\n",
    "plt.ylabel('Error = 1-Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f'Data set: {dataset_name}, Samples per signal: {signal_duration}')\n",
    "plt.ylim([0.,1.])\n",
    "plt.xlim([1,nb_epoch])\n",
    "plt.savefig(join(log_path,'network_comparison_{}-trained{}.pdf'.format(dataset_name,signal_duration)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solid curves are for the test set and dotted curves for the training set\n",
    "\n",
    "Lower is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print final performances\n",
    "\n",
    "Displays test accuracy for different algorithmes and train/test computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(log_path,'perfs-{}-{}-trained{}.txt'.format(dataset_name,'all',signal_duration)), 'w')\n",
    "\n",
    "f.write(f'#Performance evaluations, Data set: {dataset_name}, Samples per signal: {signal_duration}\\n')\n",
    "    \n",
    "f.write(f\"#{'':20s}{'Loss':15s}{'Accuracy':15s}{'Training time':20s}{'Inference time':20s}{'# Parameters':15s}\\n\")\n",
    "f.write(f\"#{'':20s}{'':15s}{'':15s}{'(s/epoch)':20s}{'(ms/signal)':20s}\\n\")\n",
    "f.write(f\"#{'-'*110}\\n\")\n",
    "\n",
    "for name_network in networks_to_plot:\n",
    "    \n",
    "    training_time_vec=  np.loadtxt(join(log_path,'history_time-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)))\n",
    "    training_time = training_time_vec[:,1].mean()\n",
    "    \n",
    "    model = load_model(join(log_path,'model-{}-{}-trained{}.h5'.format(dataset_name,name_network,signal_duration)))\n",
    "    mod_size = model.count_params()\n",
    "   \n",
    "    t = time.time()\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test,\n",
    "        verbose=False,batch_size=batch_size)\n",
    "    t_proc= 1000.0*(time.time()-t)/X_test.shape[0] #ms\n",
    "\n",
    "    f.write(f\"{from_name_to_legend[name_network]:20s}{test_loss:2.3f}{'':10s}{test_acc:2.3f}{'':10s}{training_time:>4.1f}{'':17s}{t_proc:>4.2}{'':16s}{mod_size:>10,d}\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(log_path,'perfs-{}-{}-trained{}.txt'.format(dataset_name,'all',signal_duration)), 'r')\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
