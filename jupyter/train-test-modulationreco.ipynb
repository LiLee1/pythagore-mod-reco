{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the networks for modulation recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Helion du Mas des Bourboux <helion.dumasdesbourboux'at'thalesgroup.com>\n",
    "#         Thomas Courtat <thomas.courtat'at'thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2021 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.0\n",
      "Available devices:\n",
      "['/device:CPU:0', '/device:GPU:0', '/device:GPU:1', '/device:GPU:2']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from os import mkdir\n",
    "from os.path import exists as path_exists\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "print(f'Tensorflow version {tensorflow.__version__}')\n",
    "print(f'Available devices:\\n{[x.name for x in device_lib.list_local_devices()]}')\n",
    "\n",
    "\n",
    "from pythagore_modreco.data import read_augmod, read_RML2016, read_RML2018\n",
    "from pythagore_modreco.utils import TimeHistory,split_dataset\n",
    "from pythagore_modreco import neural_nets_keras\n",
    "\n",
    "\n",
    "np.random.seed(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify the folder where your dataset(s) is/are\n",
    "data_path = <your data path>\n",
    "\n",
    "# Please specify a folder to log information during model training \n",
    "log_path = <your log path>\n",
    "\n",
    "if not path_exists(log_path):\n",
    "    mkdir(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Please chose a dataset name from:\n",
    "# AugMod\n",
    "# RadioML2016.04c\n",
    "# RadioML2016.10a\n",
    "# RadioML2016.10b\n",
    "# RadioML2018.01a\n",
    "dataset_name = \"AugMod\"\n",
    "\n",
    "# Please choose signal duration in seconds. \n",
    "# Beware, that duration should be less or equal to the chosen dataset signal lengths\n",
    "# Set to None if you want to take as much as there is in the dataset\n",
    "signal_duration = 128\n",
    "\n",
    "# Please choose a cut in SNR\n",
    "# The resulting dataset will consit in all data>=snr_cut\n",
    "# set to None if no cut\n",
    "snr_cut = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the selected dataset ; \n",
    "\n",
    "This cell outputs: \n",
    "- signals : a numpy array containing signal data \n",
    "- class_onehot : a numpy array containing one hot encoded labels associated to data \n",
    "- snrs: an array associating snr to each signal \n",
    "- class_list: a list of strings associating the modulation / signal kind name to the indexes of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"AugMod\":\n",
    "    \n",
    "    fName = join(data_path,'augmod.hdf5')\n",
    "    data_dict = read_augmod(fName)\n",
    "    \n",
    "    signals  = data_dict['signals']\n",
    "    class_idx = data_dict['modulations']\n",
    "    snrs = data_dict['snr']\n",
    "    \n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    class_list = data_dict['classes']\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.04c\":\n",
    "\n",
    "    fName = join(data_path,'2016.04C.multisnr.pkl')\n",
    "    \n",
    "    signals, class_idx, snrs, class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.10a\":\n",
    "\n",
    "    fName = join(data_path,'RML2016.10a_dict.pkl')\n",
    "    \n",
    "    signals, class_idx, snrs,class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2016.10b\":\n",
    "\n",
    "    fName = join(data_path,'RML2016.10b.dat')\n",
    "    \n",
    "    signals, class_idx, snrs,class_list = read_RML2016(fName)\n",
    "    class_onehot = to_categorical(class_idx)\n",
    "    \n",
    "elif dataset_name == \"RadioML2018.01a\":\n",
    "\n",
    "    fName = join(data_path,'GOLD_XYZ_OSC.0001_1024.hdf5')\n",
    "    \n",
    "    signals, class_onehot, snrs ,class_list = read_RML2018(fName)\n",
    "    #snrs = snrs.reshape(-1)\n",
    "    class_idx = np.argmax(class_onehot,axis=-1)\n",
    "else: \n",
    "    print('Data not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AugMod loaded, 174720 signal with shape (2, 1024)\n",
      "List of signal SNR: [0.0, 10.0, 20.0, 30.0, 40.0]\n",
      "List of modulations under consideration: ['BPSK', 'PSK8', 'QAM16', 'QAM32', 'QAM64', 'QAM8', 'QPSK']\n"
     ]
    }
   ],
   "source": [
    "snrs_list = sorted( list( set( snrs ) ) )\n",
    "print(f'{dataset_name} loaded, {signals.shape[0]} signal with shape {signals.shape[1:]}' )\n",
    "print(f'List of signal SNR: {snrs_list}')\n",
    "print(f'List of modulations under consideration: {class_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposes the data so the real/imag axis is the last as expected by deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (174720, 2, 1024)\n",
      "Transposed data shape: (174720, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial data shape: {signals.shape}')\n",
    "signals = signals.transpose((0,2,1))\n",
    "print(f'Transposed data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trunk signal to `signal_duration`samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (174720, 1024, 2)\n",
      "Trunked data shape: (174720, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "if not signal_duration is None:\n",
    "    print(f'Initial data shape: {signals.shape}')\n",
    "    signals = signals[:,:signal_duration,:]\n",
    "    print(f'Trunked data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters signal by snr if requested above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (174720, 128, 2)\n",
      "New data shape: (174720, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "if not snr_cut is None:\n",
    "    print(f'Initial data shape: {signals.shape}')\n",
    "    w = snrs>=snr_cut\n",
    "    signals = signals[w]\n",
    "    class_idx = class_idx[w]\n",
    "    snrs = snrs[w]\n",
    "    class_onehot = class_onehot[w]\n",
    "    print(f'New data shape: {signals.shape}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the power of each signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize the power of each signal\n",
    "norm = np.sqrt(np.mean(signals**2,axis=(1,2),keepdims=True))\n",
    "signals/=norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into train and test sets. Also shuffles data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (87360, 128, 2)\n",
      "Test dataset shape: (87360, 128, 2) \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, train_idx ,_,_,_, X_test,y_test,test_idx= split_dataset(signals, \n",
    "    class_onehot, \n",
    "    p_train=0.5,p_test=0.5)\n",
    "\n",
    "SNR_train = snrs[train_idx]\n",
    "SNR_test = snrs[test_idx]\n",
    "\n",
    "print(f'Train dataset shape: {X_train.shape}')\n",
    "print(f'Test dataset shape: {X_test.shape} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (87360, 128, 2), y_train shape: (87360, 7)\n",
      "X_test  shape: (87360, 128, 2), y_test  shape: (87360, 7)\n",
      "Network input shape in variable input-shp: [128, 2]\n",
      "Network output shape in variable input-shp: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_test  shape: {X_test.shape}, y_test  shape: {y_test.shape}')\n",
    "\n",
    "input_shp = list(X_train.shape[1:])\n",
    "output_shp = y_train.shape[1]\n",
    "\n",
    "print(f'Network input shape in variable input-shp: {input_shp}')\n",
    "print(f'Network output shape in variable input-shp: {output_shp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_to_tensor(X_train)\n",
    "y_train = convert_to_tensor(y_train)\n",
    "X_test = convert_to_tensor(X_test)\n",
    "y_test = convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning model training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to instanciate and train a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,name_network): \n",
    "    \n",
    "    clear_session()\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=nb_epoch, batch_size=batch_size,\n",
    "                        validation_data =( X_test , y_test ), \n",
    "                        verbose=1,\n",
    "                        callbacks=[time_callback])\n",
    "\n",
    "    model.save(join(log_path,'model-{}-{}-trained{}.h5'.format(dataset_name,name_network,signal_duration)))\n",
    "\n",
    "    data = np.array(list(zip(history.epoch, history.history['val_accuracy'], history.history['accuracy'])))\n",
    "    np.savetxt(join(log_path,'history-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)),data)\n",
    "\n",
    "    data = np.array(list(zip(history.epoch, time_callback.times)))\n",
    "    np.savetxt(join(log_path,'history_time-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)),data)\n",
    "    \n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LModCNN (ours)\n",
    "\n",
    "Generate LModCNN architecture as defined in Courtat and du Mas des Bourboux, <i>A light neural network for modulation detection under impairments</i>, ISNCC 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 8)           120       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          912       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 32)          3616      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 64)          14400     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 37,487\n",
      "Trainable params: 37,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "name_network = \"LModCNN\"\n",
    "\n",
    "dynamic_input_shp = input_shp.copy()\n",
    "dynamic_input_shp[0] = None\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(dynamic_input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 41s 128ms/step - loss: 1.8801 - accuracy: 0.1880 - val_loss: 1.6379 - val_accuracy: 0.2864\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.6230 - accuracy: 0.2912 - val_loss: 1.5900 - val_accuracy: 0.2982\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.5639 - accuracy: 0.3150 - val_loss: 1.5262 - val_accuracy: 0.3335\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 1.5294 - accuracy: 0.3359 - val_loss: 1.4817 - val_accuracy: 0.3689\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 1.4754 - accuracy: 0.3697 - val_loss: 1.4533 - val_accuracy: 0.3769\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.4198 - accuracy: 0.4002 - val_loss: 1.3595 - val_accuracy: 0.4269\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.3562 - accuracy: 0.4252 - val_loss: 1.2977 - val_accuracy: 0.4494\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.2929 - accuracy: 0.4484 - val_loss: 1.2463 - val_accuracy: 0.4560\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.2254 - accuracy: 0.4691 - val_loss: 1.1582 - val_accuracy: 0.4896\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.1738 - accuracy: 0.4858 - val_loss: 1.1182 - val_accuracy: 0.5045\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.1364 - accuracy: 0.5003 - val_loss: 1.0846 - val_accuracy: 0.5145\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.1091 - accuracy: 0.5099 - val_loss: 1.0587 - val_accuracy: 0.5302\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.0765 - accuracy: 0.5223 - val_loss: 1.0312 - val_accuracy: 0.5429\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 1.0636 - accuracy: 0.5301 - val_loss: 1.0160 - val_accuracy: 0.5500\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.0380 - accuracy: 0.5376 - val_loss: 1.0092 - val_accuracy: 0.5519\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 1.0230 - accuracy: 0.5454 - val_loss: 1.0359 - val_accuracy: 0.5371\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 2s 14ms/step - loss: 1.0138 - accuracy: 0.5504 - val_loss: 1.0133 - val_accuracy: 0.5452\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 1.0067 - accuracy: 0.5516 - val_loss: 0.9901 - val_accuracy: 0.5597\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.9933 - accuracy: 0.5574 - val_loss: 1.0048 - val_accuracy: 0.5507\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9976 - accuracy: 0.5569 - val_loss: 0.9585 - val_accuracy: 0.5705\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9788 - accuracy: 0.5631 - val_loss: 0.9760 - val_accuracy: 0.5573\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.9721 - accuracy: 0.5656 - val_loss: 0.9500 - val_accuracy: 0.5717\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9606 - accuracy: 0.5698 - val_loss: 0.9596 - val_accuracy: 0.5671\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9560 - accuracy: 0.5722 - val_loss: 0.9402 - val_accuracy: 0.5765\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9535 - accuracy: 0.5736 - val_loss: 0.9301 - val_accuracy: 0.5829\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9610 - accuracy: 0.5714 - val_loss: 0.9319 - val_accuracy: 0.5818\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9401 - accuracy: 0.5803 - val_loss: 0.9282 - val_accuracy: 0.5845\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9341 - accuracy: 0.5784 - val_loss: 0.9177 - val_accuracy: 0.5867\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.9196 - accuracy: 0.5839 - val_loss: 0.9200 - val_accuracy: 0.5861\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9153 - accuracy: 0.5891 - val_loss: 0.9114 - val_accuracy: 0.5875\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9195 - accuracy: 0.5879 - val_loss: 0.8962 - val_accuracy: 0.5953\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9104 - accuracy: 0.5905 - val_loss: 0.8963 - val_accuracy: 0.5933\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9139 - accuracy: 0.5885 - val_loss: 0.8938 - val_accuracy: 0.5924\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.9077 - accuracy: 0.5921 - val_loss: 0.8950 - val_accuracy: 0.5951\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.8972 - accuracy: 0.5949 - val_loss: 0.9088 - val_accuracy: 0.5873\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.8942 - accuracy: 0.5963 - val_loss: 0.8852 - val_accuracy: 0.5964\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8933 - accuracy: 0.5969 - val_loss: 0.8859 - val_accuracy: 0.5995\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8828 - accuracy: 0.6016 - val_loss: 0.8810 - val_accuracy: 0.6014\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8878 - accuracy: 0.5983 - val_loss: 0.8796 - val_accuracy: 0.6016\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8820 - accuracy: 0.6027 - val_loss: 0.8641 - val_accuracy: 0.6071\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8779 - accuracy: 0.6029 - val_loss: 0.8638 - val_accuracy: 0.6084\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8752 - accuracy: 0.6046 - val_loss: 0.8668 - val_accuracy: 0.6058\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8689 - accuracy: 0.6072 - val_loss: 0.8702 - val_accuracy: 0.6028\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 3s 21ms/step - loss: 0.8707 - accuracy: 0.6072 - val_loss: 0.8578 - val_accuracy: 0.6094\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8623 - accuracy: 0.6104 - val_loss: 0.8515 - val_accuracy: 0.6125\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.8560 - accuracy: 0.6126 - val_loss: 0.8569 - val_accuracy: 0.6103\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.8545 - accuracy: 0.6152 - val_loss: 0.8600 - val_accuracy: 0.6065\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8578 - accuracy: 0.6128 - val_loss: 0.8464 - val_accuracy: 0.6165\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8539 - accuracy: 0.6116 - val_loss: 0.8410 - val_accuracy: 0.6163\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.8452 - accuracy: 0.6213 - val_loss: 0.8392 - val_accuracy: 0.6183\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8460 - accuracy: 0.6168 - val_loss: 0.8336 - val_accuracy: 0.6226\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8394 - accuracy: 0.6227 - val_loss: 0.8378 - val_accuracy: 0.6231\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.8427 - accuracy: 0.6192 - val_loss: 0.8435 - val_accuracy: 0.6169\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8385 - accuracy: 0.6203 - val_loss: 0.8381 - val_accuracy: 0.6219\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8328 - accuracy: 0.6260 - val_loss: 0.8373 - val_accuracy: 0.6206\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8322 - accuracy: 0.6239 - val_loss: 0.8342 - val_accuracy: 0.6234\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 4s 20ms/step - loss: 0.8332 - accuracy: 0.6227 - val_loss: 0.8286 - val_accuracy: 0.6259\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8260 - accuracy: 0.6237 - val_loss: 0.8272 - val_accuracy: 0.6256\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8305 - accuracy: 0.6248 - val_loss: 0.8295 - val_accuracy: 0.6218\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 2s 14ms/step - loss: 0.8251 - accuracy: 0.6253 - val_loss: 0.8211 - val_accuracy: 0.6323\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.8268 - accuracy: 0.6267 - val_loss: 0.8212 - val_accuracy: 0.6296\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8198 - accuracy: 0.6297 - val_loss: 0.8197 - val_accuracy: 0.6307\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8206 - accuracy: 0.6297 - val_loss: 0.8212 - val_accuracy: 0.6283\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8159 - accuracy: 0.6316 - val_loss: 0.8288 - val_accuracy: 0.6243\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.8216 - accuracy: 0.6314 - val_loss: 0.8142 - val_accuracy: 0.6290\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8150 - accuracy: 0.6315 - val_loss: 0.8220 - val_accuracy: 0.6327\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.8117 - accuracy: 0.6321 - val_loss: 0.8524 - val_accuracy: 0.6234\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8103 - accuracy: 0.6349 - val_loss: 0.8209 - val_accuracy: 0.6305\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8142 - accuracy: 0.6337 - val_loss: 0.8112 - val_accuracy: 0.6378\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8099 - accuracy: 0.6360 - val_loss: 0.8217 - val_accuracy: 0.6298\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8049 - accuracy: 0.6375 - val_loss: 0.8039 - val_accuracy: 0.6400\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8029 - accuracy: 0.6389 - val_loss: 0.8097 - val_accuracy: 0.6402\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.8110 - accuracy: 0.6348 - val_loss: 0.8063 - val_accuracy: 0.6339\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.8001 - accuracy: 0.6395 - val_loss: 0.8051 - val_accuracy: 0.6440\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.8000 - accuracy: 0.6419 - val_loss: 0.8189 - val_accuracy: 0.6306\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7999 - accuracy: 0.6441 - val_loss: 0.8160 - val_accuracy: 0.6377\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7936 - accuracy: 0.6445 - val_loss: 0.7963 - val_accuracy: 0.6459\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7967 - accuracy: 0.6431 - val_loss: 0.8192 - val_accuracy: 0.6373\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7993 - accuracy: 0.6423 - val_loss: 0.7912 - val_accuracy: 0.6455\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7850 - accuracy: 0.6516 - val_loss: 0.8009 - val_accuracy: 0.6446\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7883 - accuracy: 0.6502 - val_loss: 0.7923 - val_accuracy: 0.6489\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7936 - accuracy: 0.6487 - val_loss: 0.7848 - val_accuracy: 0.6521\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7902 - accuracy: 0.6491 - val_loss: 0.7823 - val_accuracy: 0.6521\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7827 - accuracy: 0.6524 - val_loss: 0.7829 - val_accuracy: 0.6510\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7859 - accuracy: 0.6510 - val_loss: 0.7814 - val_accuracy: 0.6547\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7793 - accuracy: 0.6551 - val_loss: 0.7881 - val_accuracy: 0.6488\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7781 - accuracy: 0.6561 - val_loss: 0.7906 - val_accuracy: 0.6479\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7818 - accuracy: 0.6538 - val_loss: 0.7791 - val_accuracy: 0.6592\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7803 - accuracy: 0.6536 - val_loss: 0.7808 - val_accuracy: 0.6554\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7716 - accuracy: 0.6614 - val_loss: 0.7793 - val_accuracy: 0.6553\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7686 - accuracy: 0.6640 - val_loss: 0.7786 - val_accuracy: 0.6559\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.7731 - accuracy: 0.6602 - val_loss: 0.7784 - val_accuracy: 0.6582\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7632 - accuracy: 0.6648 - val_loss: 0.7735 - val_accuracy: 0.6584\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.7695 - accuracy: 0.6593 - val_loss: 0.7715 - val_accuracy: 0.6615\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7730 - accuracy: 0.6618 - val_loss: 0.7745 - val_accuracy: 0.6622\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7685 - accuracy: 0.6629 - val_loss: 0.7613 - val_accuracy: 0.6664\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7588 - accuracy: 0.6679 - val_loss: 0.7656 - val_accuracy: 0.6692\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7573 - accuracy: 0.6708 - val_loss: 0.7583 - val_accuracy: 0.6665\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7495 - accuracy: 0.6717 - val_loss: 0.7511 - val_accuracy: 0.6733\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7530 - accuracy: 0.6736 - val_loss: 0.7486 - val_accuracy: 0.6771\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7479 - accuracy: 0.6749 - val_loss: 0.7588 - val_accuracy: 0.6708\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7497 - accuracy: 0.6779 - val_loss: 0.7495 - val_accuracy: 0.6747\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.7420 - accuracy: 0.6770 - val_loss: 0.7449 - val_accuracy: 0.6749\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.7362 - accuracy: 0.6818 - val_loss: 0.7426 - val_accuracy: 0.6787\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.7358 - accuracy: 0.6806 - val_loss: 0.7313 - val_accuracy: 0.6841\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7266 - accuracy: 0.6832 - val_loss: 0.7321 - val_accuracy: 0.6807\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7332 - accuracy: 0.6834 - val_loss: 0.7254 - val_accuracy: 0.6842\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7305 - accuracy: 0.6820 - val_loss: 0.7313 - val_accuracy: 0.6816\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7264 - accuracy: 0.6877 - val_loss: 0.7212 - val_accuracy: 0.6888\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7150 - accuracy: 0.6929 - val_loss: 0.7294 - val_accuracy: 0.6844\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7168 - accuracy: 0.6900 - val_loss: 0.7228 - val_accuracy: 0.6898\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7156 - accuracy: 0.6924 - val_loss: 0.7264 - val_accuracy: 0.6877\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7072 - accuracy: 0.6945 - val_loss: 0.7164 - val_accuracy: 0.6910\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.7021 - accuracy: 0.6974 - val_loss: 0.7165 - val_accuracy: 0.6890\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.7083 - accuracy: 0.6965 - val_loss: 0.7061 - val_accuracy: 0.6938\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.7068 - accuracy: 0.6964 - val_loss: 0.7082 - val_accuracy: 0.6951\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6978 - accuracy: 0.7000 - val_loss: 0.7102 - val_accuracy: 0.6943\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6939 - accuracy: 0.7003 - val_loss: 0.7059 - val_accuracy: 0.6985\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6953 - accuracy: 0.7012 - val_loss: 0.7115 - val_accuracy: 0.6939\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6923 - accuracy: 0.7017 - val_loss: 0.7001 - val_accuracy: 0.6988\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6956 - accuracy: 0.7013 - val_loss: 0.7177 - val_accuracy: 0.6894\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6938 - accuracy: 0.7009 - val_loss: 0.7014 - val_accuracy: 0.6941\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6916 - accuracy: 0.7024 - val_loss: 0.7006 - val_accuracy: 0.6991\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6937 - accuracy: 0.7020 - val_loss: 0.7040 - val_accuracy: 0.6976\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6847 - accuracy: 0.7065 - val_loss: 0.6913 - val_accuracy: 0.6999\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6841 - accuracy: 0.7070 - val_loss: 0.6867 - val_accuracy: 0.7028\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6775 - accuracy: 0.7076 - val_loss: 0.6967 - val_accuracy: 0.7006\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6822 - accuracy: 0.7081 - val_loss: 0.6865 - val_accuracy: 0.7050\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6715 - accuracy: 0.7101 - val_loss: 0.6917 - val_accuracy: 0.6998\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6701 - accuracy: 0.7113 - val_loss: 0.6876 - val_accuracy: 0.7034\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6668 - accuracy: 0.7134 - val_loss: 0.6806 - val_accuracy: 0.7060\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6688 - accuracy: 0.7136 - val_loss: 0.6794 - val_accuracy: 0.7078\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6664 - accuracy: 0.7119 - val_loss: 0.6837 - val_accuracy: 0.7039\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6709 - accuracy: 0.7089 - val_loss: 0.6858 - val_accuracy: 0.7036\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6657 - accuracy: 0.7133 - val_loss: 0.7070 - val_accuracy: 0.6953\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6682 - accuracy: 0.7117 - val_loss: 0.6768 - val_accuracy: 0.7066\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6563 - accuracy: 0.7168 - val_loss: 0.6825 - val_accuracy: 0.7073\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6576 - accuracy: 0.7164 - val_loss: 0.6737 - val_accuracy: 0.7107\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6588 - accuracy: 0.7175 - val_loss: 0.6749 - val_accuracy: 0.7116\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6579 - accuracy: 0.7192 - val_loss: 0.6841 - val_accuracy: 0.7079\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 3s 15ms/step - loss: 0.6499 - accuracy: 0.7217 - val_loss: 0.6701 - val_accuracy: 0.7116\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.6571 - accuracy: 0.7164 - val_loss: 0.6765 - val_accuracy: 0.7075\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.6529 - accuracy: 0.7193 - val_loss: 0.6708 - val_accuracy: 0.7109\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6460 - accuracy: 0.7247 - val_loss: 0.6740 - val_accuracy: 0.7113\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6523 - accuracy: 0.7200 - val_loss: 0.6705 - val_accuracy: 0.7101\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6485 - accuracy: 0.7204 - val_loss: 0.6766 - val_accuracy: 0.7113\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6516 - accuracy: 0.7215 - val_loss: 0.6660 - val_accuracy: 0.7139\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6493 - accuracy: 0.7219 - val_loss: 0.6706 - val_accuracy: 0.7119\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6425 - accuracy: 0.7239 - val_loss: 0.6749 - val_accuracy: 0.7112\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6502 - accuracy: 0.7232 - val_loss: 0.6758 - val_accuracy: 0.7112\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6429 - accuracy: 0.7243 - val_loss: 0.6669 - val_accuracy: 0.7152\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6454 - accuracy: 0.7231 - val_loss: 0.6655 - val_accuracy: 0.7140\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6415 - accuracy: 0.7247 - val_loss: 0.6811 - val_accuracy: 0.7103\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6440 - accuracy: 0.7210 - val_loss: 0.6678 - val_accuracy: 0.7142\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6385 - accuracy: 0.7260 - val_loss: 0.6632 - val_accuracy: 0.7163\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 2s 14ms/step - loss: 0.6300 - accuracy: 0.7290 - val_loss: 0.6605 - val_accuracy: 0.7180\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6362 - accuracy: 0.7250 - val_loss: 0.6667 - val_accuracy: 0.7133\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6341 - accuracy: 0.7281 - val_loss: 0.6615 - val_accuracy: 0.7168\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6392 - accuracy: 0.7250 - val_loss: 0.6665 - val_accuracy: 0.7164\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6286 - accuracy: 0.7296 - val_loss: 0.6621 - val_accuracy: 0.7165\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6325 - accuracy: 0.7289 - val_loss: 0.6613 - val_accuracy: 0.7154\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6334 - accuracy: 0.7303 - val_loss: 0.6623 - val_accuracy: 0.7174\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6291 - accuracy: 0.7303 - val_loss: 0.6599 - val_accuracy: 0.7183\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6305 - accuracy: 0.7284 - val_loss: 0.6575 - val_accuracy: 0.7178\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6299 - accuracy: 0.7308 - val_loss: 0.6671 - val_accuracy: 0.7162\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6252 - accuracy: 0.7321 - val_loss: 0.6759 - val_accuracy: 0.7113\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6280 - accuracy: 0.7287 - val_loss: 0.6805 - val_accuracy: 0.7120\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6322 - accuracy: 0.7303 - val_loss: 0.6629 - val_accuracy: 0.7165\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6251 - accuracy: 0.7313 - val_loss: 0.6556 - val_accuracy: 0.7195\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6250 - accuracy: 0.7311 - val_loss: 0.6646 - val_accuracy: 0.7168\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6258 - accuracy: 0.7316 - val_loss: 0.6603 - val_accuracy: 0.7173\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6230 - accuracy: 0.7304 - val_loss: 0.6850 - val_accuracy: 0.7138\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6272 - accuracy: 0.7300 - val_loss: 0.6575 - val_accuracy: 0.7204\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6279 - accuracy: 0.7303 - val_loss: 0.6572 - val_accuracy: 0.7152\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6179 - accuracy: 0.7344 - val_loss: 0.6710 - val_accuracy: 0.7142\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6236 - accuracy: 0.7327 - val_loss: 0.6576 - val_accuracy: 0.7204\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6178 - accuracy: 0.7352 - val_loss: 0.6547 - val_accuracy: 0.7202\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6204 - accuracy: 0.7330 - val_loss: 0.7025 - val_accuracy: 0.7053\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6221 - accuracy: 0.7356 - val_loss: 0.6502 - val_accuracy: 0.7223\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6160 - accuracy: 0.7348 - val_loss: 0.6555 - val_accuracy: 0.7212\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6253 - accuracy: 0.7307 - val_loss: 0.6669 - val_accuracy: 0.7185\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6142 - accuracy: 0.7358 - val_loss: 0.6658 - val_accuracy: 0.7186\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6183 - accuracy: 0.7356 - val_loss: 0.6523 - val_accuracy: 0.7223\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6179 - accuracy: 0.7329 - val_loss: 0.6479 - val_accuracy: 0.7230\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 3s 15ms/step - loss: 0.6124 - accuracy: 0.7378 - val_loss: 0.6542 - val_accuracy: 0.7202\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 0.6110 - accuracy: 0.7368 - val_loss: 0.6527 - val_accuracy: 0.7225\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6110 - accuracy: 0.7373 - val_loss: 0.6532 - val_accuracy: 0.7211\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.6142 - accuracy: 0.7356 - val_loss: 0.6585 - val_accuracy: 0.7199\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6157 - accuracy: 0.7350 - val_loss: 0.6551 - val_accuracy: 0.7215\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6057 - accuracy: 0.7403 - val_loss: 0.6580 - val_accuracy: 0.7185\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6064 - accuracy: 0.7407 - val_loss: 0.6491 - val_accuracy: 0.7243\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6013 - accuracy: 0.7402 - val_loss: 0.6548 - val_accuracy: 0.7226\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 3s 21ms/step - loss: 0.6062 - accuracy: 0.7398 - val_loss: 0.6626 - val_accuracy: 0.7205\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6059 - accuracy: 0.7401 - val_loss: 0.6611 - val_accuracy: 0.7216\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6005 - accuracy: 0.7409 - val_loss: 0.6554 - val_accuracy: 0.7211\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.6006 - accuracy: 0.7426 - val_loss: 0.6670 - val_accuracy: 0.7166\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6012 - accuracy: 0.7418 - val_loss: 0.6550 - val_accuracy: 0.7233\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 4s 23ms/step - loss: 0.6056 - accuracy: 0.7388 - val_loss: 0.6616 - val_accuracy: 0.7217\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.6031 - accuracy: 0.7396 - val_loss: 0.6467 - val_accuracy: 0.7240\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 4s 24ms/step - loss: 0.5990 - accuracy: 0.7432 - val_loss: 0.6586 - val_accuracy: 0.7212\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LModCNNResNet Relu (ours)\n",
    "\n",
    "Generate LModCNN with residual connexion architecture as defined in Courtat and du Mas des Bourboux, <i>A light neural network for modulation detection under impairments</i>, ISNCC 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 8)      24          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 8)      456         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 8)      456         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 8)      0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 8)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 16)     144         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 16)     1808        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 16)     1808        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 16)     0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 16)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 32)     544         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 32)     7200        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 32)     7200        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 32)     0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 32)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 64)     2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 64)     28736       conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 64)     28736       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 64)     0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 64)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          16640       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            1799        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 97,663\n",
      "Trainable params: 97,663\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "name_network = \"LModCNNResNetRelu\"\n",
    "\n",
    "dynamic_input_shp = input_shp.copy()\n",
    "dynamic_input_shp[0] = None\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(dynamic_input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 93s 302ms/step - loss: 1.8576 - accuracy: 0.1951 - val_loss: 1.5099 - val_accuracy: 0.3558\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 1.3931 - accuracy: 0.3754 - val_loss: 1.1735 - val_accuracy: 0.4575\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 1.1861 - accuracy: 0.4537 - val_loss: 1.0960 - val_accuracy: 0.5004\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 1.1003 - accuracy: 0.4984 - val_loss: 1.1030 - val_accuracy: 0.4880\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 1.0640 - accuracy: 0.5141 - val_loss: 1.0521 - val_accuracy: 0.5219\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 1.0396 - accuracy: 0.5232 - val_loss: 1.0049 - val_accuracy: 0.5358\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 1.0230 - accuracy: 0.5294 - val_loss: 1.0806 - val_accuracy: 0.5059\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 1.0112 - accuracy: 0.5360 - val_loss: 0.9969 - val_accuracy: 0.5309\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 1.0012 - accuracy: 0.5396 - val_loss: 0.9698 - val_accuracy: 0.5488\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.9759 - accuracy: 0.5505 - val_loss: 0.9755 - val_accuracy: 0.5550\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.9654 - accuracy: 0.5545 - val_loss: 0.9629 - val_accuracy: 0.5571\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.9481 - accuracy: 0.5591 - val_loss: 0.9769 - val_accuracy: 0.5486\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.9363 - accuracy: 0.5671 - val_loss: 0.9485 - val_accuracy: 0.5663\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.9232 - accuracy: 0.5743 - val_loss: 0.9081 - val_accuracy: 0.5883\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.9131 - accuracy: 0.5828 - val_loss: 0.9975 - val_accuracy: 0.5631\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.9088 - accuracy: 0.5873 - val_loss: 0.8733 - val_accuracy: 0.6009\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8770 - accuracy: 0.6007 - val_loss: 0.8560 - val_accuracy: 0.6163\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.8640 - accuracy: 0.6118 - val_loss: 0.8701 - val_accuracy: 0.6001\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.8582 - accuracy: 0.6146 - val_loss: 0.8503 - val_accuracy: 0.6250\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.8329 - accuracy: 0.6277 - val_loss: 0.8430 - val_accuracy: 0.6293\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.8355 - accuracy: 0.6320 - val_loss: 0.8179 - val_accuracy: 0.6377\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.8200 - accuracy: 0.6378 - val_loss: 0.8012 - val_accuracy: 0.6481\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 6s 34ms/step - loss: 0.7926 - accuracy: 0.6535 - val_loss: 0.8077 - val_accuracy: 0.6518\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.7903 - accuracy: 0.6574 - val_loss: 0.7719 - val_accuracy: 0.6606\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.7683 - accuracy: 0.6663 - val_loss: 0.7719 - val_accuracy: 0.6648\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.7682 - accuracy: 0.6694 - val_loss: 0.7549 - val_accuracy: 0.6688\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.7531 - accuracy: 0.6711 - val_loss: 0.7425 - val_accuracy: 0.6742\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.7475 - accuracy: 0.6748 - val_loss: 0.7410 - val_accuracy: 0.6775\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.7435 - accuracy: 0.6776 - val_loss: 0.7270 - val_accuracy: 0.6800\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.7186 - accuracy: 0.6905 - val_loss: 0.7261 - val_accuracy: 0.6814\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.7160 - accuracy: 0.6923 - val_loss: 0.7335 - val_accuracy: 0.6806\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.7047 - accuracy: 0.6925 - val_loss: 0.6930 - val_accuracy: 0.6959\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.6841 - accuracy: 0.6989 - val_loss: 0.7007 - val_accuracy: 0.6952\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.6853 - accuracy: 0.7037 - val_loss: 0.6955 - val_accuracy: 0.6975\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.6851 - accuracy: 0.7020 - val_loss: 0.6985 - val_accuracy: 0.6919\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6742 - accuracy: 0.7054 - val_loss: 0.6832 - val_accuracy: 0.7016\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6697 - accuracy: 0.7088 - val_loss: 0.6990 - val_accuracy: 0.6943\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.6675 - accuracy: 0.7109 - val_loss: 0.6749 - val_accuracy: 0.7083\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.6570 - accuracy: 0.7127 - val_loss: 0.6639 - val_accuracy: 0.7071\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.6551 - accuracy: 0.7135 - val_loss: 0.6696 - val_accuracy: 0.7095\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6455 - accuracy: 0.7198 - val_loss: 0.6845 - val_accuracy: 0.7033\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6439 - accuracy: 0.7205 - val_loss: 0.6620 - val_accuracy: 0.7140\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6409 - accuracy: 0.7232 - val_loss: 0.6592 - val_accuracy: 0.7162\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6299 - accuracy: 0.7258 - val_loss: 0.6364 - val_accuracy: 0.7227\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6294 - accuracy: 0.7297 - val_loss: 0.6353 - val_accuracy: 0.7245\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.6225 - accuracy: 0.7286 - val_loss: 0.6428 - val_accuracy: 0.7242\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 6s 37ms/step - loss: 0.6227 - accuracy: 0.7301 - val_loss: 0.6372 - val_accuracy: 0.7234\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.6180 - accuracy: 0.7332 - val_loss: 0.6417 - val_accuracy: 0.7239\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.6149 - accuracy: 0.7326 - val_loss: 0.6354 - val_accuracy: 0.7248\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.6087 - accuracy: 0.7354 - val_loss: 0.6535 - val_accuracy: 0.7222\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6092 - accuracy: 0.7359 - val_loss: 0.6317 - val_accuracy: 0.7257\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.5979 - accuracy: 0.7391 - val_loss: 0.6722 - val_accuracy: 0.7163\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5973 - accuracy: 0.7411 - val_loss: 0.6236 - val_accuracy: 0.7323\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5970 - accuracy: 0.7412 - val_loss: 0.6244 - val_accuracy: 0.7297\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 8s 50ms/step - loss: 0.5859 - accuracy: 0.7464 - val_loss: 0.6244 - val_accuracy: 0.7291\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5872 - accuracy: 0.7466 - val_loss: 0.6303 - val_accuracy: 0.7317\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5917 - accuracy: 0.7443 - val_loss: 0.6336 - val_accuracy: 0.7275\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5775 - accuracy: 0.7471 - val_loss: 0.6244 - val_accuracy: 0.7294\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5749 - accuracy: 0.7508 - val_loss: 0.6236 - val_accuracy: 0.7318\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5745 - accuracy: 0.7516 - val_loss: 0.6467 - val_accuracy: 0.7302\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5770 - accuracy: 0.7485 - val_loss: 0.6186 - val_accuracy: 0.7329\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5719 - accuracy: 0.7509 - val_loss: 0.6187 - val_accuracy: 0.7353\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 0.5795 - accuracy: 0.7488 - val_loss: 0.6262 - val_accuracy: 0.7303\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.5640 - accuracy: 0.7549 - val_loss: 0.6291 - val_accuracy: 0.7325\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.5670 - accuracy: 0.7540 - val_loss: 0.6239 - val_accuracy: 0.7362\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 8s 49ms/step - loss: 0.5604 - accuracy: 0.7582 - val_loss: 0.6249 - val_accuracy: 0.7368\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5643 - accuracy: 0.7575 - val_loss: 0.6208 - val_accuracy: 0.7364\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5581 - accuracy: 0.7587 - val_loss: 0.6323 - val_accuracy: 0.7292\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 9s 50ms/step - loss: 0.5574 - accuracy: 0.7594 - val_loss: 0.6209 - val_accuracy: 0.7371\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5555 - accuracy: 0.7597 - val_loss: 0.6052 - val_accuracy: 0.7397\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5427 - accuracy: 0.7631 - val_loss: 0.6314 - val_accuracy: 0.7328\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5576 - accuracy: 0.7563 - val_loss: 0.6121 - val_accuracy: 0.7399\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5511 - accuracy: 0.7613 - val_loss: 0.6202 - val_accuracy: 0.7386\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5427 - accuracy: 0.7650 - val_loss: 0.6213 - val_accuracy: 0.7383\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.5460 - accuracy: 0.7642 - val_loss: 0.6315 - val_accuracy: 0.7293\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5379 - accuracy: 0.7650 - val_loss: 0.6101 - val_accuracy: 0.7400\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5258 - accuracy: 0.7702 - val_loss: 0.6112 - val_accuracy: 0.7392\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5323 - accuracy: 0.7677 - val_loss: 0.6266 - val_accuracy: 0.7382\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5319 - accuracy: 0.7683 - val_loss: 0.6246 - val_accuracy: 0.7381\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5310 - accuracy: 0.7686 - val_loss: 0.6212 - val_accuracy: 0.7395\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5362 - accuracy: 0.7671 - val_loss: 0.6257 - val_accuracy: 0.7373\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5248 - accuracy: 0.7718 - val_loss: 0.6184 - val_accuracy: 0.7399\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5235 - accuracy: 0.7705 - val_loss: 0.6434 - val_accuracy: 0.7397\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5233 - accuracy: 0.7724 - val_loss: 0.6240 - val_accuracy: 0.7379\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.5130 - accuracy: 0.7762 - val_loss: 0.6348 - val_accuracy: 0.7404\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5144 - accuracy: 0.7766 - val_loss: 0.6339 - val_accuracy: 0.7416\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5111 - accuracy: 0.7777 - val_loss: 0.6222 - val_accuracy: 0.7408\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5219 - accuracy: 0.7721 - val_loss: 0.6238 - val_accuracy: 0.7399\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5108 - accuracy: 0.7779 - val_loss: 0.6329 - val_accuracy: 0.7377\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5115 - accuracy: 0.7762 - val_loss: 0.6172 - val_accuracy: 0.7437\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5046 - accuracy: 0.7813 - val_loss: 0.6399 - val_accuracy: 0.7389\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5100 - accuracy: 0.7762 - val_loss: 0.6444 - val_accuracy: 0.7374\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5037 - accuracy: 0.7790 - val_loss: 0.6207 - val_accuracy: 0.7400\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5027 - accuracy: 0.7809 - val_loss: 0.6532 - val_accuracy: 0.7346\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5053 - accuracy: 0.7819 - val_loss: 0.6275 - val_accuracy: 0.7446\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4987 - accuracy: 0.7819 - val_loss: 0.6242 - val_accuracy: 0.7417\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.5001 - accuracy: 0.7832 - val_loss: 0.6184 - val_accuracy: 0.7435\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4920 - accuracy: 0.7848 - val_loss: 0.6607 - val_accuracy: 0.7376\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4978 - accuracy: 0.7831 - val_loss: 0.6286 - val_accuracy: 0.7448\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4987 - accuracy: 0.7827 - val_loss: 0.6647 - val_accuracy: 0.7387\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4933 - accuracy: 0.7835 - val_loss: 0.6680 - val_accuracy: 0.7352\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4920 - accuracy: 0.7843 - val_loss: 0.6380 - val_accuracy: 0.7412\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4970 - accuracy: 0.7840 - val_loss: 0.6318 - val_accuracy: 0.7470\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4793 - accuracy: 0.7909 - val_loss: 0.6406 - val_accuracy: 0.7427\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4841 - accuracy: 0.7890 - val_loss: 0.6488 - val_accuracy: 0.7404\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4801 - accuracy: 0.7916 - val_loss: 0.6476 - val_accuracy: 0.7464\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4802 - accuracy: 0.7910 - val_loss: 0.6480 - val_accuracy: 0.7376\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.4876 - accuracy: 0.7865 - val_loss: 0.6448 - val_accuracy: 0.7442\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4825 - accuracy: 0.7901 - val_loss: 0.6556 - val_accuracy: 0.7423\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4704 - accuracy: 0.7933 - val_loss: 0.6467 - val_accuracy: 0.7422\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4761 - accuracy: 0.7906 - val_loss: 0.6549 - val_accuracy: 0.7461\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4715 - accuracy: 0.7932 - val_loss: 0.6520 - val_accuracy: 0.7463\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4660 - accuracy: 0.7967 - val_loss: 0.6609 - val_accuracy: 0.7435\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4683 - accuracy: 0.7933 - val_loss: 0.6675 - val_accuracy: 0.7396\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4764 - accuracy: 0.7924 - val_loss: 0.6685 - val_accuracy: 0.7444\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4648 - accuracy: 0.7962 - val_loss: 0.6775 - val_accuracy: 0.7437\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4695 - accuracy: 0.7914 - val_loss: 0.6833 - val_accuracy: 0.7416\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4748 - accuracy: 0.7938 - val_loss: 0.6742 - val_accuracy: 0.7437\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 6s 33ms/step - loss: 0.4628 - accuracy: 0.7961 - val_loss: 0.7109 - val_accuracy: 0.7418\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4621 - accuracy: 0.7976 - val_loss: 0.6751 - val_accuracy: 0.7404\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4611 - accuracy: 0.7971 - val_loss: 0.6558 - val_accuracy: 0.7464\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4520 - accuracy: 0.8031 - val_loss: 0.6669 - val_accuracy: 0.7445\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4629 - accuracy: 0.7965 - val_loss: 0.6751 - val_accuracy: 0.7443\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4489 - accuracy: 0.8037 - val_loss: 0.7068 - val_accuracy: 0.7362\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4565 - accuracy: 0.8004 - val_loss: 0.6947 - val_accuracy: 0.7440\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4510 - accuracy: 0.8016 - val_loss: 0.6750 - val_accuracy: 0.7398\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4501 - accuracy: 0.8017 - val_loss: 0.7058 - val_accuracy: 0.7421\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4556 - accuracy: 0.8001 - val_loss: 0.6974 - val_accuracy: 0.7448\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4476 - accuracy: 0.8017 - val_loss: 0.6887 - val_accuracy: 0.7422\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 6s 36ms/step - loss: 0.4509 - accuracy: 0.8022 - val_loss: 0.7071 - val_accuracy: 0.7406\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4463 - accuracy: 0.8057 - val_loss: 0.7107 - val_accuracy: 0.7439\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 8s 49ms/step - loss: 0.4430 - accuracy: 0.8039 - val_loss: 0.6744 - val_accuracy: 0.7451\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4420 - accuracy: 0.8064 - val_loss: 0.7093 - val_accuracy: 0.7449\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4505 - accuracy: 0.8021 - val_loss: 0.7060 - val_accuracy: 0.7410\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4432 - accuracy: 0.8058 - val_loss: 0.6940 - val_accuracy: 0.7462\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4359 - accuracy: 0.8083 - val_loss: 0.7074 - val_accuracy: 0.7427\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 8s 49ms/step - loss: 0.4371 - accuracy: 0.8075 - val_loss: 0.7300 - val_accuracy: 0.7434\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 8s 49ms/step - loss: 0.4441 - accuracy: 0.8050 - val_loss: 0.7241 - val_accuracy: 0.7428\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4369 - accuracy: 0.8093 - val_loss: 0.7463 - val_accuracy: 0.7400\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4375 - accuracy: 0.8076 - val_loss: 0.6978 - val_accuracy: 0.7411\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.4405 - accuracy: 0.8070 - val_loss: 0.7072 - val_accuracy: 0.7409\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4346 - accuracy: 0.8090 - val_loss: 0.7141 - val_accuracy: 0.7440\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4420 - accuracy: 0.8059 - val_loss: 0.7321 - val_accuracy: 0.7434\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4311 - accuracy: 0.8104 - val_loss: 0.7395 - val_accuracy: 0.7417\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4330 - accuracy: 0.8080 - val_loss: 0.7542 - val_accuracy: 0.7435\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4354 - accuracy: 0.8086 - val_loss: 0.7337 - val_accuracy: 0.7406\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4258 - accuracy: 0.8121 - val_loss: 0.7593 - val_accuracy: 0.7424\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4297 - accuracy: 0.8109 - val_loss: 0.7050 - val_accuracy: 0.7409\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4377 - accuracy: 0.8087 - val_loss: 0.7428 - val_accuracy: 0.7391\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4433 - accuracy: 0.8047 - val_loss: 0.7313 - val_accuracy: 0.7435\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4231 - accuracy: 0.8137 - val_loss: 0.7484 - val_accuracy: 0.7430\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4249 - accuracy: 0.8120 - val_loss: 0.7532 - val_accuracy: 0.7425\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4274 - accuracy: 0.8118 - val_loss: 0.7661 - val_accuracy: 0.7425\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4267 - accuracy: 0.8124 - val_loss: 0.7614 - val_accuracy: 0.7410\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4186 - accuracy: 0.8161 - val_loss: 0.8058 - val_accuracy: 0.7381\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4133 - accuracy: 0.8181 - val_loss: 0.7699 - val_accuracy: 0.7426\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4337 - accuracy: 0.8112 - val_loss: 0.7978 - val_accuracy: 0.7341\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4179 - accuracy: 0.8166 - val_loss: 0.7798 - val_accuracy: 0.7401\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4116 - accuracy: 0.8193 - val_loss: 0.7876 - val_accuracy: 0.7418\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.8057 - val_accuracy: 0.7371\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4226 - accuracy: 0.8142 - val_loss: 0.7879 - val_accuracy: 0.7422\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.4240 - accuracy: 0.8146 - val_loss: 0.7603 - val_accuracy: 0.7423\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 6s 32ms/step - loss: 0.4176 - accuracy: 0.8155 - val_loss: 0.8177 - val_accuracy: 0.7372\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 8s 48ms/step - loss: 0.4048 - accuracy: 0.8216 - val_loss: 0.7913 - val_accuracy: 0.7398\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4171 - accuracy: 0.8180 - val_loss: 0.8324 - val_accuracy: 0.7407\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4227 - accuracy: 0.8153 - val_loss: 0.7831 - val_accuracy: 0.7450\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4148 - accuracy: 0.8167 - val_loss: 0.8137 - val_accuracy: 0.7419\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4142 - accuracy: 0.8187 - val_loss: 0.8175 - val_accuracy: 0.7410\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4172 - accuracy: 0.8176 - val_loss: 0.8625 - val_accuracy: 0.7379\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 8s 47ms/step - loss: 0.4125 - accuracy: 0.8192 - val_loss: 0.8142 - val_accuracy: 0.7412\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.4108 - accuracy: 0.8211 - val_loss: 0.8296 - val_accuracy: 0.7410\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4034 - accuracy: 0.8225 - val_loss: 0.7534 - val_accuracy: 0.7429\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.4125 - accuracy: 0.8181 - val_loss: 0.7994 - val_accuracy: 0.7386\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.4156 - accuracy: 0.8182 - val_loss: 0.8076 - val_accuracy: 0.7415\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.4027 - accuracy: 0.8220 - val_loss: 0.7697 - val_accuracy: 0.7372\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4092 - accuracy: 0.8208 - val_loss: 0.8801 - val_accuracy: 0.7391\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.4080 - accuracy: 0.8222 - val_loss: 0.7958 - val_accuracy: 0.7391\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3985 - accuracy: 0.8247 - val_loss: 0.8362 - val_accuracy: 0.7355\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4067 - accuracy: 0.8230 - val_loss: 0.8479 - val_accuracy: 0.7349\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4213 - accuracy: 0.8158 - val_loss: 0.8822 - val_accuracy: 0.7412\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.3899 - accuracy: 0.8275 - val_loss: 0.8487 - val_accuracy: 0.7402\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.4026 - accuracy: 0.8222 - val_loss: 0.8370 - val_accuracy: 0.7397\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 0.3994 - accuracy: 0.8243 - val_loss: 0.7982 - val_accuracy: 0.7383\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4121 - accuracy: 0.8209 - val_loss: 0.8408 - val_accuracy: 0.7394\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.4028 - accuracy: 0.8246 - val_loss: 0.8405 - val_accuracy: 0.7367\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4108 - accuracy: 0.8232 - val_loss: 0.8311 - val_accuracy: 0.7414\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.3901 - accuracy: 0.8280 - val_loss: 0.8908 - val_accuracy: 0.7383\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3886 - accuracy: 0.8295 - val_loss: 0.8639 - val_accuracy: 0.7384\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4029 - accuracy: 0.8241 - val_loss: 0.8584 - val_accuracy: 0.7399\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3874 - accuracy: 0.8300 - val_loss: 0.8680 - val_accuracy: 0.7366\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.4018 - accuracy: 0.8237 - val_loss: 0.8661 - val_accuracy: 0.7394\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3920 - accuracy: 0.8279 - val_loss: 0.8747 - val_accuracy: 0.7405\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3865 - accuracy: 0.8308 - val_loss: 0.8846 - val_accuracy: 0.7406\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.3981 - accuracy: 0.8277 - val_loss: 0.8884 - val_accuracy: 0.7398\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.3906 - accuracy: 0.8297 - val_loss: 0.8642 - val_accuracy: 0.7412\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.3859 - accuracy: 0.8336 - val_loss: 0.8663 - val_accuracy: 0.7397\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 6s 34ms/step - loss: 0.3859 - accuracy: 0.8309 - val_loss: 0.8995 - val_accuracy: 0.7371\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3889 - accuracy: 0.8297 - val_loss: 0.9550 - val_accuracy: 0.7371\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.3844 - accuracy: 0.8314 - val_loss: 0.8852 - val_accuracy: 0.7402\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 5s 30ms/step - loss: 0.3870 - accuracy: 0.8316 - val_loss: 0.8846 - val_accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLConvNet\n",
    "\n",
    "Generate RMLConvNet as defined in O'Shea et Al., <i>Convolutional radio modulation recognition networks</i>, 2016\n",
    "The implementation is an adaptation of\n",
    "https://github.com/radioML/examples/blob/master/modulation_recognition/RML2016.10a_VTCNN2_example.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 128, 2, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 132, 2, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 130, 2, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 130, 2, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 134, 2, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 132, 1, 80)        122960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 132, 1, 80)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10560)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2703616   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 2,829,399\n",
      "Trainable params: 2,829,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "name_network = \"RMLConvNet\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 26s 97ms/step - loss: 1.8482 - accuracy: 0.1901 - val_loss: 1.5959 - val_accuracy: 0.2836\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 1.5924 - accuracy: 0.2946 - val_loss: 1.3568 - val_accuracy: 0.4201\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 1.3439 - accuracy: 0.4136 - val_loss: 1.1438 - val_accuracy: 0.4934\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 1.1853 - accuracy: 0.4716 - val_loss: 1.0729 - val_accuracy: 0.5026\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 1.1094 - accuracy: 0.5019 - val_loss: 1.0120 - val_accuracy: 0.5413\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 1.0513 - accuracy: 0.5254 - val_loss: 1.0013 - val_accuracy: 0.5367\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 1.0187 - accuracy: 0.5421 - val_loss: 0.9492 - val_accuracy: 0.5646\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9934 - accuracy: 0.5499 - val_loss: 0.9409 - val_accuracy: 0.5667\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9749 - accuracy: 0.5608 - val_loss: 0.9322 - val_accuracy: 0.5715\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9622 - accuracy: 0.5641 - val_loss: 0.9446 - val_accuracy: 0.5618\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.9524 - accuracy: 0.5753 - val_loss: 0.9052 - val_accuracy: 0.5803\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.9360 - accuracy: 0.5776 - val_loss: 0.9076 - val_accuracy: 0.5802\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9262 - accuracy: 0.5821 - val_loss: 0.8943 - val_accuracy: 0.5872\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9126 - accuracy: 0.5928 - val_loss: 0.9004 - val_accuracy: 0.5806\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.9045 - accuracy: 0.5954 - val_loss: 0.9123 - val_accuracy: 0.5780\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8959 - accuracy: 0.6021 - val_loss: 0.8828 - val_accuracy: 0.5940\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8924 - accuracy: 0.6040 - val_loss: 0.8802 - val_accuracy: 0.5930\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8778 - accuracy: 0.6090 - val_loss: 0.8800 - val_accuracy: 0.5936\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.8715 - accuracy: 0.6142 - val_loss: 0.8759 - val_accuracy: 0.5927\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8568 - accuracy: 0.6215 - val_loss: 0.8840 - val_accuracy: 0.5888\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.8561 - accuracy: 0.6229 - val_loss: 0.8800 - val_accuracy: 0.5967\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8425 - accuracy: 0.6287 - val_loss: 0.8772 - val_accuracy: 0.5925\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.8374 - accuracy: 0.6311 - val_loss: 0.8774 - val_accuracy: 0.5912\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.8347 - accuracy: 0.6361 - val_loss: 0.9007 - val_accuracy: 0.5826\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8266 - accuracy: 0.6393 - val_loss: 0.8775 - val_accuracy: 0.5951\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8234 - accuracy: 0.6413 - val_loss: 0.8727 - val_accuracy: 0.5947\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8106 - accuracy: 0.6496 - val_loss: 0.8654 - val_accuracy: 0.5983\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.8044 - accuracy: 0.6507 - val_loss: 0.8698 - val_accuracy: 0.5965\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8023 - accuracy: 0.6518 - val_loss: 0.8740 - val_accuracy: 0.5977\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7931 - accuracy: 0.6552 - val_loss: 0.8803 - val_accuracy: 0.5888\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.7892 - accuracy: 0.6600 - val_loss: 0.8784 - val_accuracy: 0.5947\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.7847 - accuracy: 0.6608 - val_loss: 0.8702 - val_accuracy: 0.5994\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7763 - accuracy: 0.6666 - val_loss: 0.8712 - val_accuracy: 0.5954\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7714 - accuracy: 0.6692 - val_loss: 0.8723 - val_accuracy: 0.5997\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7674 - accuracy: 0.6721 - val_loss: 0.8730 - val_accuracy: 0.6008\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.7662 - accuracy: 0.6745 - val_loss: 0.8714 - val_accuracy: 0.5992\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 10s 61ms/step - loss: 0.7530 - accuracy: 0.6796 - val_loss: 0.8674 - val_accuracy: 0.6013\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7487 - accuracy: 0.6823 - val_loss: 0.8695 - val_accuracy: 0.5966\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7419 - accuracy: 0.6858 - val_loss: 0.8682 - val_accuracy: 0.6014\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7381 - accuracy: 0.6862 - val_loss: 0.8804 - val_accuracy: 0.5984\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7434 - accuracy: 0.6871 - val_loss: 0.8706 - val_accuracy: 0.5988\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7280 - accuracy: 0.6917 - val_loss: 0.8684 - val_accuracy: 0.5996\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7227 - accuracy: 0.6966 - val_loss: 0.8693 - val_accuracy: 0.6018\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7295 - accuracy: 0.6923 - val_loss: 0.8722 - val_accuracy: 0.5998\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.7155 - accuracy: 0.6996 - val_loss: 0.8866 - val_accuracy: 0.5917\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7078 - accuracy: 0.7031 - val_loss: 0.8678 - val_accuracy: 0.6021\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7068 - accuracy: 0.7044 - val_loss: 0.8670 - val_accuracy: 0.6037\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.7030 - accuracy: 0.7059 - val_loss: 0.8687 - val_accuracy: 0.6043\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7001 - accuracy: 0.7097 - val_loss: 0.8891 - val_accuracy: 0.5980\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6970 - accuracy: 0.7073 - val_loss: 0.8903 - val_accuracy: 0.5965\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 8s 49ms/step - loss: 0.6992 - accuracy: 0.7094 - val_loss: 0.8784 - val_accuracy: 0.6017\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 9s 53ms/step - loss: 0.6927 - accuracy: 0.7145 - val_loss: 0.8924 - val_accuracy: 0.5909\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6865 - accuracy: 0.7154 - val_loss: 0.8751 - val_accuracy: 0.6021\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6835 - accuracy: 0.7172 - val_loss: 0.8725 - val_accuracy: 0.6029\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6798 - accuracy: 0.7192 - val_loss: 0.8779 - val_accuracy: 0.6025\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.6768 - accuracy: 0.7170 - val_loss: 0.8718 - val_accuracy: 0.6020\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6724 - accuracy: 0.7218 - val_loss: 0.8811 - val_accuracy: 0.6018\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6687 - accuracy: 0.7234 - val_loss: 0.8738 - val_accuracy: 0.6050\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6587 - accuracy: 0.7286 - val_loss: 0.8921 - val_accuracy: 0.5927\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6614 - accuracy: 0.7260 - val_loss: 0.8815 - val_accuracy: 0.5974\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6524 - accuracy: 0.7322 - val_loss: 0.8755 - val_accuracy: 0.6002\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6593 - accuracy: 0.7284 - val_loss: 0.8700 - val_accuracy: 0.6051\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6569 - accuracy: 0.7294 - val_loss: 0.8778 - val_accuracy: 0.6020\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6502 - accuracy: 0.7340 - val_loss: 0.8786 - val_accuracy: 0.6008\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6402 - accuracy: 0.7348 - val_loss: 0.8725 - val_accuracy: 0.6038\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6425 - accuracy: 0.7378 - val_loss: 0.8823 - val_accuracy: 0.5968\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6456 - accuracy: 0.7373 - val_loss: 0.8784 - val_accuracy: 0.6006\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6367 - accuracy: 0.7371 - val_loss: 0.8769 - val_accuracy: 0.6023\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6374 - accuracy: 0.7388 - val_loss: 0.8827 - val_accuracy: 0.5984\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 10s 57ms/step - loss: 0.6388 - accuracy: 0.7397 - val_loss: 0.8751 - val_accuracy: 0.6017\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6300 - accuracy: 0.7442 - val_loss: 0.8735 - val_accuracy: 0.6046\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 10s 60ms/step - loss: 0.6256 - accuracy: 0.7453 - val_loss: 0.8721 - val_accuracy: 0.6055\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 10s 59ms/step - loss: 0.6184 - accuracy: 0.7487 - val_loss: 0.8823 - val_accuracy: 0.5995\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6165 - accuracy: 0.7462 - val_loss: 0.8872 - val_accuracy: 0.5993\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6139 - accuracy: 0.7509 - val_loss: 0.8773 - val_accuracy: 0.6007\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6141 - accuracy: 0.7496 - val_loss: 0.8766 - val_accuracy: 0.6029\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6151 - accuracy: 0.7500 - val_loss: 0.8813 - val_accuracy: 0.6041\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.6094 - accuracy: 0.7516 - val_loss: 0.8799 - val_accuracy: 0.6013\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6002 - accuracy: 0.7583 - val_loss: 0.8825 - val_accuracy: 0.6017\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.6054 - accuracy: 0.7559 - val_loss: 0.8757 - val_accuracy: 0.6068\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5975 - accuracy: 0.7578 - val_loss: 0.8828 - val_accuracy: 0.6032\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5939 - accuracy: 0.7639 - val_loss: 0.8887 - val_accuracy: 0.6008\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5948 - accuracy: 0.7592 - val_loss: 0.8906 - val_accuracy: 0.5996\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 10s 58ms/step - loss: 0.5908 - accuracy: 0.7597 - val_loss: 0.8897 - val_accuracy: 0.6038\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5883 - accuracy: 0.7636 - val_loss: 0.8807 - val_accuracy: 0.6043\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 11s 66ms/step - loss: 0.5922 - accuracy: 0.7636 - val_loss: 0.8859 - val_accuracy: 0.6019\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 11s 63ms/step - loss: 0.5897 - accuracy: 0.7641 - val_loss: 0.8804 - val_accuracy: 0.6032\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 11s 64ms/step - loss: 0.5782 - accuracy: 0.7682 - val_loss: 0.8893 - val_accuracy: 0.6007\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 10s 61ms/step - loss: 0.5777 - accuracy: 0.7658 - val_loss: 0.8822 - val_accuracy: 0.6026\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 10s 57ms/step - loss: 0.5812 - accuracy: 0.7663 - val_loss: 0.8870 - val_accuracy: 0.6018\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5754 - accuracy: 0.7695 - val_loss: 0.8918 - val_accuracy: 0.6006\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5738 - accuracy: 0.7707 - val_loss: 0.8847 - val_accuracy: 0.6024\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5695 - accuracy: 0.7704 - val_loss: 0.8857 - val_accuracy: 0.6048\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5686 - accuracy: 0.7742 - val_loss: 0.8925 - val_accuracy: 0.5982\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5653 - accuracy: 0.7734 - val_loss: 0.8834 - val_accuracy: 0.6043\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5632 - accuracy: 0.7752 - val_loss: 0.8932 - val_accuracy: 0.5970\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5596 - accuracy: 0.7755 - val_loss: 0.8897 - val_accuracy: 0.6012\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5582 - accuracy: 0.7769 - val_loss: 0.8926 - val_accuracy: 0.6038\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5624 - accuracy: 0.7756 - val_loss: 0.8865 - val_accuracy: 0.6054\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5579 - accuracy: 0.7787 - val_loss: 0.8879 - val_accuracy: 0.6045\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5531 - accuracy: 0.7797 - val_loss: 0.8831 - val_accuracy: 0.6052\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5515 - accuracy: 0.7818 - val_loss: 0.8919 - val_accuracy: 0.6014\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5520 - accuracy: 0.7808 - val_loss: 0.8846 - val_accuracy: 0.6058\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5428 - accuracy: 0.7831 - val_loss: 0.8868 - val_accuracy: 0.6015\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5456 - accuracy: 0.7819 - val_loss: 0.8917 - val_accuracy: 0.6051\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5546 - accuracy: 0.7791 - val_loss: 0.8873 - val_accuracy: 0.6038\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5518 - accuracy: 0.7806 - val_loss: 0.8877 - val_accuracy: 0.6038\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5482 - accuracy: 0.7833 - val_loss: 0.8841 - val_accuracy: 0.6046\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5422 - accuracy: 0.7857 - val_loss: 0.8896 - val_accuracy: 0.6039\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5367 - accuracy: 0.7872 - val_loss: 0.8877 - val_accuracy: 0.6058\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5361 - accuracy: 0.7877 - val_loss: 0.8913 - val_accuracy: 0.6050\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5382 - accuracy: 0.7853 - val_loss: 0.9129 - val_accuracy: 0.6032\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5381 - accuracy: 0.7868 - val_loss: 0.8918 - val_accuracy: 0.6071\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5312 - accuracy: 0.7894 - val_loss: 0.8940 - val_accuracy: 0.6050\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5328 - accuracy: 0.7910 - val_loss: 0.8884 - val_accuracy: 0.6040\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5323 - accuracy: 0.7885 - val_loss: 0.8934 - val_accuracy: 0.6024\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5286 - accuracy: 0.7902 - val_loss: 0.8855 - val_accuracy: 0.6075\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.5259 - accuracy: 0.7923 - val_loss: 0.9032 - val_accuracy: 0.5997\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5267 - accuracy: 0.7930 - val_loss: 0.8926 - val_accuracy: 0.6056\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5318 - accuracy: 0.7886 - val_loss: 0.8886 - val_accuracy: 0.6047\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5210 - accuracy: 0.7968 - val_loss: 0.8951 - val_accuracy: 0.6059\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5176 - accuracy: 0.7953 - val_loss: 0.9001 - val_accuracy: 0.6036\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5160 - accuracy: 0.7978 - val_loss: 0.8926 - val_accuracy: 0.6053\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5146 - accuracy: 0.7961 - val_loss: 0.9010 - val_accuracy: 0.6012\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5141 - accuracy: 0.7971 - val_loss: 0.9010 - val_accuracy: 0.6027\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5165 - accuracy: 0.7966 - val_loss: 0.8956 - val_accuracy: 0.6055\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5095 - accuracy: 0.8021 - val_loss: 0.8927 - val_accuracy: 0.6062\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5151 - accuracy: 0.8000 - val_loss: 0.8926 - val_accuracy: 0.6064\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5088 - accuracy: 0.8000 - val_loss: 0.8965 - val_accuracy: 0.6068\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5093 - accuracy: 0.8006 - val_loss: 0.8906 - val_accuracy: 0.6047\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5093 - accuracy: 0.8018 - val_loss: 0.8908 - val_accuracy: 0.6078\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4983 - accuracy: 0.8032 - val_loss: 0.8924 - val_accuracy: 0.6067\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4941 - accuracy: 0.8066 - val_loss: 0.8925 - val_accuracy: 0.6045\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5007 - accuracy: 0.8030 - val_loss: 0.8923 - val_accuracy: 0.6056\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5012 - accuracy: 0.8018 - val_loss: 0.9117 - val_accuracy: 0.5985\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5064 - accuracy: 0.8030 - val_loss: 0.8960 - val_accuracy: 0.6033\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4964 - accuracy: 0.8066 - val_loss: 0.8934 - val_accuracy: 0.6099\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5023 - accuracy: 0.8024 - val_loss: 0.8979 - val_accuracy: 0.6060\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4943 - accuracy: 0.8083 - val_loss: 0.8966 - val_accuracy: 0.6050\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4993 - accuracy: 0.8062 - val_loss: 0.8989 - val_accuracy: 0.6058\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5003 - accuracy: 0.8048 - val_loss: 0.8927 - val_accuracy: 0.6054\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4924 - accuracy: 0.8095 - val_loss: 0.8933 - val_accuracy: 0.6058\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4885 - accuracy: 0.8092 - val_loss: 0.8946 - val_accuracy: 0.6049\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4850 - accuracy: 0.8110 - val_loss: 0.8934 - val_accuracy: 0.6057\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4933 - accuracy: 0.8071 - val_loss: 0.8916 - val_accuracy: 0.6090\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4877 - accuracy: 0.8086 - val_loss: 0.8947 - val_accuracy: 0.6049\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4909 - accuracy: 0.8099 - val_loss: 0.8996 - val_accuracy: 0.6079\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4891 - accuracy: 0.8101 - val_loss: 0.9047 - val_accuracy: 0.6045\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4856 - accuracy: 0.8126 - val_loss: 0.8980 - val_accuracy: 0.6076\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4923 - accuracy: 0.8089 - val_loss: 0.9039 - val_accuracy: 0.6041\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4897 - accuracy: 0.8100 - val_loss: 0.8994 - val_accuracy: 0.6073\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4792 - accuracy: 0.8154 - val_loss: 0.9124 - val_accuracy: 0.6077\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4834 - accuracy: 0.8123 - val_loss: 0.8998 - val_accuracy: 0.6068\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4884 - accuracy: 0.8111 - val_loss: 0.8969 - val_accuracy: 0.6050\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4808 - accuracy: 0.8137 - val_loss: 0.9046 - val_accuracy: 0.6055\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4847 - accuracy: 0.8098 - val_loss: 0.9028 - val_accuracy: 0.6031\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4755 - accuracy: 0.8146 - val_loss: 0.8997 - val_accuracy: 0.6063\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4697 - accuracy: 0.8189 - val_loss: 0.9014 - val_accuracy: 0.6055\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4732 - accuracy: 0.8167 - val_loss: 0.9018 - val_accuracy: 0.6022\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4793 - accuracy: 0.8134 - val_loss: 0.9012 - val_accuracy: 0.6030\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4799 - accuracy: 0.8135 - val_loss: 0.8989 - val_accuracy: 0.6082\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4666 - accuracy: 0.8188 - val_loss: 0.9032 - val_accuracy: 0.6030\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4683 - accuracy: 0.8185 - val_loss: 0.8983 - val_accuracy: 0.6082\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4744 - accuracy: 0.8160 - val_loss: 0.8988 - val_accuracy: 0.6085\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4716 - accuracy: 0.8172 - val_loss: 0.9015 - val_accuracy: 0.6070\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4693 - accuracy: 0.8165 - val_loss: 0.9030 - val_accuracy: 0.6052\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4630 - accuracy: 0.8219 - val_loss: 0.8937 - val_accuracy: 0.6084\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4705 - accuracy: 0.8203 - val_loss: 0.9013 - val_accuracy: 0.6091\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4618 - accuracy: 0.8229 - val_loss: 0.8976 - val_accuracy: 0.6081\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4604 - accuracy: 0.8220 - val_loss: 0.8981 - val_accuracy: 0.6068\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4634 - accuracy: 0.8212 - val_loss: 0.8958 - val_accuracy: 0.6083\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4613 - accuracy: 0.8203 - val_loss: 0.8967 - val_accuracy: 0.6071\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4656 - accuracy: 0.8206 - val_loss: 0.9097 - val_accuracy: 0.6045\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4665 - accuracy: 0.8197 - val_loss: 0.8994 - val_accuracy: 0.6070\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4632 - accuracy: 0.8232 - val_loss: 0.9024 - val_accuracy: 0.6055\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4588 - accuracy: 0.8219 - val_loss: 0.9086 - val_accuracy: 0.6023\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4604 - accuracy: 0.8223 - val_loss: 0.8995 - val_accuracy: 0.6061\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4546 - accuracy: 0.8236 - val_loss: 0.9014 - val_accuracy: 0.6064\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4587 - accuracy: 0.8239 - val_loss: 0.9071 - val_accuracy: 0.6053\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4609 - accuracy: 0.8216 - val_loss: 0.8980 - val_accuracy: 0.6041\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4582 - accuracy: 0.8237 - val_loss: 0.9038 - val_accuracy: 0.6072\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4587 - accuracy: 0.8231 - val_loss: 0.9048 - val_accuracy: 0.6045\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4558 - accuracy: 0.8250 - val_loss: 0.8991 - val_accuracy: 0.6096\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4505 - accuracy: 0.8254 - val_loss: 0.9074 - val_accuracy: 0.6013\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4572 - accuracy: 0.8243 - val_loss: 0.8975 - val_accuracy: 0.6077\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4543 - accuracy: 0.8244 - val_loss: 0.9042 - val_accuracy: 0.6049\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4496 - accuracy: 0.8265 - val_loss: 0.9020 - val_accuracy: 0.6088\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4495 - accuracy: 0.8260 - val_loss: 0.9029 - val_accuracy: 0.6085\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4475 - accuracy: 0.8270 - val_loss: 0.9087 - val_accuracy: 0.6075\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4461 - accuracy: 0.8278 - val_loss: 0.9052 - val_accuracy: 0.6070\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4472 - accuracy: 0.8261 - val_loss: 0.9088 - val_accuracy: 0.6067\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4528 - accuracy: 0.8272 - val_loss: 0.9036 - val_accuracy: 0.6070\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4430 - accuracy: 0.8308 - val_loss: 0.9108 - val_accuracy: 0.6063\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4512 - accuracy: 0.8266 - val_loss: 0.9070 - val_accuracy: 0.6079\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4472 - accuracy: 0.8298 - val_loss: 0.9062 - val_accuracy: 0.6077\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4378 - accuracy: 0.8306 - val_loss: 0.9088 - val_accuracy: 0.6078\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4335 - accuracy: 0.8338 - val_loss: 0.9014 - val_accuracy: 0.6077\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4350 - accuracy: 0.8331 - val_loss: 0.9127 - val_accuracy: 0.6048\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4322 - accuracy: 0.8352 - val_loss: 0.9040 - val_accuracy: 0.6082\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4391 - accuracy: 0.8318 - val_loss: 0.9015 - val_accuracy: 0.6086\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLCNNVGG\n",
    "\n",
    "Generate RML CNN/VGG  as defined in O'Shea et Al., <i>Over-the-Air Deep Learning Based Radio Signal Classification</i>,  2018. The implementation is an adaptation of https://github.com/leena201818/radioml/blob/master/rmlmodels/VGGLikeModel.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 128, 64)           960       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16, 64)            28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 8, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 4, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 199,111\n",
      "Trainable params: 199,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "name_network = \"RMLCNNVGG\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 86s 264ms/step - loss: 1.9318 - accuracy: 0.1566 - val_loss: 1.6265 - val_accuracy: 0.2654\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.6246 - accuracy: 0.2700 - val_loss: 1.5939 - val_accuracy: 0.2853\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.5832 - accuracy: 0.2843 - val_loss: 1.5587 - val_accuracy: 0.2966\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.5255 - accuracy: 0.3180 - val_loss: 1.1931 - val_accuracy: 0.4331\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.1855 - accuracy: 0.4330 - val_loss: 1.1008 - val_accuracy: 0.4587\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 1.0911 - accuracy: 0.4610 - val_loss: 1.0833 - val_accuracy: 0.4625\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.0525 - accuracy: 0.4693 - val_loss: 1.0641 - val_accuracy: 0.4742\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 1.0225 - accuracy: 0.4804 - val_loss: 1.0214 - val_accuracy: 0.4812\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 1.0037 - accuracy: 0.4827 - val_loss: 1.0189 - val_accuracy: 0.4770\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9907 - accuracy: 0.4905 - val_loss: 1.0455 - val_accuracy: 0.4739\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9872 - accuracy: 0.4912 - val_loss: 0.9991 - val_accuracy: 0.4865\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9565 - accuracy: 0.5038 - val_loss: 1.0208 - val_accuracy: 0.4783\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9653 - accuracy: 0.4994 - val_loss: 1.0061 - val_accuracy: 0.4843\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9436 - accuracy: 0.5043 - val_loss: 1.0228 - val_accuracy: 0.4784\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.9407 - accuracy: 0.5097 - val_loss: 1.0125 - val_accuracy: 0.4883\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.9234 - accuracy: 0.5112 - val_loss: 1.0293 - val_accuracy: 0.4778\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.9110 - accuracy: 0.5192 - val_loss: 1.0404 - val_accuracy: 0.4787\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.9036 - accuracy: 0.5245 - val_loss: 1.0461 - val_accuracy: 0.4836\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.8996 - accuracy: 0.5271 - val_loss: 1.0760 - val_accuracy: 0.4804\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.8783 - accuracy: 0.5348 - val_loss: 1.0550 - val_accuracy: 0.4883\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.8667 - accuracy: 0.5414 - val_loss: 1.0821 - val_accuracy: 0.4885\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8638 - accuracy: 0.5417 - val_loss: 1.0766 - val_accuracy: 0.4863\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.8507 - accuracy: 0.5476 - val_loss: 1.1133 - val_accuracy: 0.4852\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8286 - accuracy: 0.5592 - val_loss: 1.1414 - val_accuracy: 0.4851\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8090 - accuracy: 0.5671 - val_loss: 1.1270 - val_accuracy: 0.4992\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.8169 - accuracy: 0.5685 - val_loss: 1.1760 - val_accuracy: 0.4955\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7887 - accuracy: 0.5801 - val_loss: 1.2032 - val_accuracy: 0.4973\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7866 - accuracy: 0.5863 - val_loss: 1.2239 - val_accuracy: 0.4972\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7597 - accuracy: 0.5989 - val_loss: 1.2802 - val_accuracy: 0.4914\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7539 - accuracy: 0.6076 - val_loss: 1.2369 - val_accuracy: 0.5051\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7372 - accuracy: 0.6197 - val_loss: 1.2578 - val_accuracy: 0.5069\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7353 - accuracy: 0.6269 - val_loss: 1.2652 - val_accuracy: 0.5130\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.7076 - accuracy: 0.6394 - val_loss: 1.3062 - val_accuracy: 0.5136\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.7058 - accuracy: 0.6408 - val_loss: 1.3384 - val_accuracy: 0.5217\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6778 - accuracy: 0.6562 - val_loss: 1.3645 - val_accuracy: 0.5255\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6525 - accuracy: 0.6718 - val_loss: 1.3016 - val_accuracy: 0.5440\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.6307 - accuracy: 0.6846 - val_loss: 1.3728 - val_accuracy: 0.5452\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.6299 - accuracy: 0.6901 - val_loss: 1.3605 - val_accuracy: 0.5427\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5987 - accuracy: 0.7025 - val_loss: 1.3646 - val_accuracy: 0.5532\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5857 - accuracy: 0.7072 - val_loss: 1.3709 - val_accuracy: 0.5541\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5652 - accuracy: 0.7170 - val_loss: 1.3847 - val_accuracy: 0.5524\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5558 - accuracy: 0.7235 - val_loss: 1.3998 - val_accuracy: 0.5559\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5391 - accuracy: 0.7313 - val_loss: 1.3873 - val_accuracy: 0.5580\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5366 - accuracy: 0.7313 - val_loss: 1.4718 - val_accuracy: 0.5535\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.5351 - accuracy: 0.7354 - val_loss: 1.4705 - val_accuracy: 0.5563\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5162 - accuracy: 0.7434 - val_loss: 1.5716 - val_accuracy: 0.5542\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.5026 - accuracy: 0.7484 - val_loss: 1.5747 - val_accuracy: 0.5608\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4821 - accuracy: 0.7617 - val_loss: 1.5759 - val_accuracy: 0.5546\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4768 - accuracy: 0.7627 - val_loss: 1.4981 - val_accuracy: 0.5573\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4611 - accuracy: 0.7697 - val_loss: 1.6338 - val_accuracy: 0.5580\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4629 - accuracy: 0.7700 - val_loss: 1.6328 - val_accuracy: 0.5552\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4552 - accuracy: 0.7758 - val_loss: 1.6579 - val_accuracy: 0.5564\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.4442 - accuracy: 0.7792 - val_loss: 1.6449 - val_accuracy: 0.5537\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4317 - accuracy: 0.7864 - val_loss: 1.7212 - val_accuracy: 0.5559\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4226 - accuracy: 0.7876 - val_loss: 1.6447 - val_accuracy: 0.5541\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.4157 - accuracy: 0.7933 - val_loss: 1.7242 - val_accuracy: 0.5515\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3997 - accuracy: 0.7975 - val_loss: 1.7723 - val_accuracy: 0.5588\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3825 - accuracy: 0.8084 - val_loss: 1.8008 - val_accuracy: 0.5587\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3920 - accuracy: 0.8036 - val_loss: 1.8679 - val_accuracy: 0.5570\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3848 - accuracy: 0.8081 - val_loss: 1.9107 - val_accuracy: 0.5547\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3732 - accuracy: 0.8118 - val_loss: 1.9281 - val_accuracy: 0.5525\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3611 - accuracy: 0.8188 - val_loss: 1.9044 - val_accuracy: 0.5521\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3582 - accuracy: 0.8197 - val_loss: 1.9842 - val_accuracy: 0.5579\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3442 - accuracy: 0.8260 - val_loss: 2.1479 - val_accuracy: 0.5559\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3504 - accuracy: 0.8257 - val_loss: 2.0096 - val_accuracy: 0.5585\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3321 - accuracy: 0.8323 - val_loss: 2.0899 - val_accuracy: 0.5576\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3429 - accuracy: 0.8305 - val_loss: 2.1060 - val_accuracy: 0.5575\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3344 - accuracy: 0.8334 - val_loss: 1.9885 - val_accuracy: 0.5570\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3252 - accuracy: 0.8358 - val_loss: 2.0740 - val_accuracy: 0.5557\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3196 - accuracy: 0.8408 - val_loss: 2.1405 - val_accuracy: 0.5592\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3117 - accuracy: 0.8420 - val_loss: 2.1030 - val_accuracy: 0.5568\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.3132 - accuracy: 0.8448 - val_loss: 2.2183 - val_accuracy: 0.5590\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.2990 - accuracy: 0.8515 - val_loss: 2.2077 - val_accuracy: 0.5559\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.3077 - accuracy: 0.8488 - val_loss: 2.3570 - val_accuracy: 0.5567\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2992 - accuracy: 0.8535 - val_loss: 2.3205 - val_accuracy: 0.5553\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2994 - accuracy: 0.8523 - val_loss: 2.2393 - val_accuracy: 0.5602\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2941 - accuracy: 0.8564 - val_loss: 2.4151 - val_accuracy: 0.5561\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2950 - accuracy: 0.8567 - val_loss: 2.2972 - val_accuracy: 0.5592\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2803 - accuracy: 0.8647 - val_loss: 2.3510 - val_accuracy: 0.5586\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2902 - accuracy: 0.8629 - val_loss: 2.2636 - val_accuracy: 0.5605\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2662 - accuracy: 0.8719 - val_loss: 2.2637 - val_accuracy: 0.5601\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2783 - accuracy: 0.8680 - val_loss: 2.3945 - val_accuracy: 0.5600\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2617 - accuracy: 0.8774 - val_loss: 2.3110 - val_accuracy: 0.5590\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2605 - accuracy: 0.8780 - val_loss: 2.4073 - val_accuracy: 0.5534\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2659 - accuracy: 0.8793 - val_loss: 2.4110 - val_accuracy: 0.5605\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2589 - accuracy: 0.8817 - val_loss: 2.5016 - val_accuracy: 0.5610\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2550 - accuracy: 0.8855 - val_loss: 2.3223 - val_accuracy: 0.5584\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2489 - accuracy: 0.8896 - val_loss: 2.3695 - val_accuracy: 0.5598\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2441 - accuracy: 0.8926 - val_loss: 2.4669 - val_accuracy: 0.5555\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2420 - accuracy: 0.8953 - val_loss: 2.5154 - val_accuracy: 0.5576\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2286 - accuracy: 0.9016 - val_loss: 2.5126 - val_accuracy: 0.5554\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2284 - accuracy: 0.9004 - val_loss: 2.5304 - val_accuracy: 0.5583\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2204 - accuracy: 0.9056 - val_loss: 2.5352 - val_accuracy: 0.5565\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2430 - accuracy: 0.8982 - val_loss: 2.4819 - val_accuracy: 0.5594\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2195 - accuracy: 0.9070 - val_loss: 2.4798 - val_accuracy: 0.5550\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2146 - accuracy: 0.9104 - val_loss: 2.6618 - val_accuracy: 0.5595\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2123 - accuracy: 0.9115 - val_loss: 2.5990 - val_accuracy: 0.5571\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2240 - accuracy: 0.9077 - val_loss: 2.7189 - val_accuracy: 0.5569\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.2138 - accuracy: 0.9119 - val_loss: 2.5784 - val_accuracy: 0.5579\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.2005 - accuracy: 0.9190 - val_loss: 2.6192 - val_accuracy: 0.5552\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1925 - accuracy: 0.9207 - val_loss: 2.6988 - val_accuracy: 0.5595\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1835 - accuracy: 0.9271 - val_loss: 2.6554 - val_accuracy: 0.5575\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1897 - accuracy: 0.9239 - val_loss: 2.6310 - val_accuracy: 0.5550\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1975 - accuracy: 0.9226 - val_loss: 2.6061 - val_accuracy: 0.5590\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1745 - accuracy: 0.9316 - val_loss: 2.7170 - val_accuracy: 0.5582\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1711 - accuracy: 0.9329 - val_loss: 2.7154 - val_accuracy: 0.5554\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1720 - accuracy: 0.9327 - val_loss: 2.7218 - val_accuracy: 0.5589\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1630 - accuracy: 0.9361 - val_loss: 2.7698 - val_accuracy: 0.5613\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1638 - accuracy: 0.9366 - val_loss: 2.6456 - val_accuracy: 0.5531\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1687 - accuracy: 0.9354 - val_loss: 2.7843 - val_accuracy: 0.5574\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1652 - accuracy: 0.9360 - val_loss: 2.9436 - val_accuracy: 0.5548\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1558 - accuracy: 0.9403 - val_loss: 2.7483 - val_accuracy: 0.5584\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1506 - accuracy: 0.9417 - val_loss: 2.7317 - val_accuracy: 0.5550\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1626 - accuracy: 0.9396 - val_loss: 2.8667 - val_accuracy: 0.5588\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1437 - accuracy: 0.9478 - val_loss: 2.7849 - val_accuracy: 0.5591\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1503 - accuracy: 0.9437 - val_loss: 2.8135 - val_accuracy: 0.5577\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1389 - accuracy: 0.9482 - val_loss: 2.9121 - val_accuracy: 0.5558\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1495 - accuracy: 0.9436 - val_loss: 2.9163 - val_accuracy: 0.5568\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1411 - accuracy: 0.9476 - val_loss: 2.9280 - val_accuracy: 0.5555\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1408 - accuracy: 0.9485 - val_loss: 2.7047 - val_accuracy: 0.5546\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1321 - accuracy: 0.9513 - val_loss: 2.8785 - val_accuracy: 0.5578\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1370 - accuracy: 0.9501 - val_loss: 2.9123 - val_accuracy: 0.5583\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1312 - accuracy: 0.9517 - val_loss: 2.9270 - val_accuracy: 0.5591\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1424 - accuracy: 0.9479 - val_loss: 2.9080 - val_accuracy: 0.5577\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1169 - accuracy: 0.9570 - val_loss: 2.8669 - val_accuracy: 0.5599\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1270 - accuracy: 0.9528 - val_loss: 2.8686 - val_accuracy: 0.5573\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1212 - accuracy: 0.9561 - val_loss: 2.9312 - val_accuracy: 0.5602\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1241 - accuracy: 0.9537 - val_loss: 2.9489 - val_accuracy: 0.5574\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1172 - accuracy: 0.9583 - val_loss: 2.9118 - val_accuracy: 0.5583\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1204 - accuracy: 0.9554 - val_loss: 2.8679 - val_accuracy: 0.5564\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1212 - accuracy: 0.9567 - val_loss: 2.9185 - val_accuracy: 0.5569\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1149 - accuracy: 0.9584 - val_loss: 2.9691 - val_accuracy: 0.5581\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1138 - accuracy: 0.9584 - val_loss: 2.9214 - val_accuracy: 0.5590\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1228 - accuracy: 0.9556 - val_loss: 2.9360 - val_accuracy: 0.5563\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1102 - accuracy: 0.9607 - val_loss: 2.8942 - val_accuracy: 0.5564\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1100 - accuracy: 0.9610 - val_loss: 2.9120 - val_accuracy: 0.5596\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1056 - accuracy: 0.9624 - val_loss: 3.0818 - val_accuracy: 0.5560\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1093 - accuracy: 0.9611 - val_loss: 3.1346 - val_accuracy: 0.5569\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1102 - accuracy: 0.9596 - val_loss: 3.0262 - val_accuracy: 0.5585\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1173 - accuracy: 0.9577 - val_loss: 3.0273 - val_accuracy: 0.5594\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.1098 - accuracy: 0.9612 - val_loss: 2.9894 - val_accuracy: 0.5575\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1024 - accuracy: 0.9632 - val_loss: 2.9800 - val_accuracy: 0.5614\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1061 - accuracy: 0.9624 - val_loss: 2.9326 - val_accuracy: 0.5543\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.1070 - accuracy: 0.9606 - val_loss: 3.0205 - val_accuracy: 0.5583\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 2.9271 - val_accuracy: 0.5579\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1150 - accuracy: 0.9590 - val_loss: 3.0941 - val_accuracy: 0.5598\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1007 - accuracy: 0.9646 - val_loss: 3.1192 - val_accuracy: 0.5600\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1036 - accuracy: 0.9633 - val_loss: 3.0378 - val_accuracy: 0.5571\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1017 - accuracy: 0.9642 - val_loss: 3.0419 - val_accuracy: 0.5593\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.1010 - accuracy: 0.9637 - val_loss: 3.1451 - val_accuracy: 0.5594\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 2.9711 - val_accuracy: 0.5572\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 3s 21ms/step - loss: 0.1096 - accuracy: 0.9613 - val_loss: 3.0205 - val_accuracy: 0.5576\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0945 - accuracy: 0.9670 - val_loss: 3.0951 - val_accuracy: 0.5581\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0936 - accuracy: 0.9670 - val_loss: 3.0768 - val_accuracy: 0.5573\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 4s 22ms/step - loss: 0.0930 - accuracy: 0.9670 - val_loss: 3.0552 - val_accuracy: 0.5560\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 3.0805 - val_accuracy: 0.5576\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0976 - accuracy: 0.9648 - val_loss: 3.1519 - val_accuracy: 0.5592\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 3.0341 - val_accuracy: 0.5578\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0966 - accuracy: 0.9666 - val_loss: 3.0254 - val_accuracy: 0.5576\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0957 - accuracy: 0.9664 - val_loss: 3.0969 - val_accuracy: 0.5566\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0929 - accuracy: 0.9681 - val_loss: 3.0120 - val_accuracy: 0.5595\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0882 - accuracy: 0.9698 - val_loss: 3.0403 - val_accuracy: 0.5574\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 3.0837 - val_accuracy: 0.5538\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0851 - accuracy: 0.9700 - val_loss: 3.0658 - val_accuracy: 0.5558\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0913 - accuracy: 0.9686 - val_loss: 3.1058 - val_accuracy: 0.5568\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 4s 21ms/step - loss: 0.0853 - accuracy: 0.9706 - val_loss: 3.1282 - val_accuracy: 0.5594\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0967 - accuracy: 0.9668 - val_loss: 2.9917 - val_accuracy: 0.5583\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0907 - accuracy: 0.9682 - val_loss: 3.0352 - val_accuracy: 0.5581\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0844 - accuracy: 0.9704 - val_loss: 3.0670 - val_accuracy: 0.5591\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0857 - accuracy: 0.9699 - val_loss: 3.1547 - val_accuracy: 0.5564\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0881 - accuracy: 0.9691 - val_loss: 3.1294 - val_accuracy: 0.5598\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0971 - accuracy: 0.9651 - val_loss: 3.0888 - val_accuracy: 0.5597\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0779 - accuracy: 0.9736 - val_loss: 3.1245 - val_accuracy: 0.5587\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0883 - accuracy: 0.9697 - val_loss: 3.2064 - val_accuracy: 0.5535\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0831 - accuracy: 0.9707 - val_loss: 3.1233 - val_accuracy: 0.5576\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 3.1140 - val_accuracy: 0.5598\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0800 - accuracy: 0.9717 - val_loss: 3.1446 - val_accuracy: 0.5563\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0823 - accuracy: 0.9717 - val_loss: 3.0092 - val_accuracy: 0.5601\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0842 - accuracy: 0.9706 - val_loss: 3.1132 - val_accuracy: 0.5574\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0860 - accuracy: 0.9705 - val_loss: 3.0279 - val_accuracy: 0.5593\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0803 - accuracy: 0.9728 - val_loss: 3.1896 - val_accuracy: 0.5542\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 2.9718 - val_accuracy: 0.5586\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0725 - accuracy: 0.9754 - val_loss: 3.0216 - val_accuracy: 0.5579\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0768 - accuracy: 0.9735 - val_loss: 3.0378 - val_accuracy: 0.5616\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0786 - accuracy: 0.9728 - val_loss: 3.0626 - val_accuracy: 0.5594\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 3.0818 - val_accuracy: 0.5596\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0812 - accuracy: 0.9723 - val_loss: 3.1960 - val_accuracy: 0.5612\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 3.1041 - val_accuracy: 0.5599\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 3.0327 - val_accuracy: 0.5614\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0727 - accuracy: 0.9757 - val_loss: 3.0467 - val_accuracy: 0.5573\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0792 - accuracy: 0.9727 - val_loss: 3.2548 - val_accuracy: 0.5590\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.0769 - accuracy: 0.9734 - val_loss: 3.1413 - val_accuracy: 0.5581\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0780 - accuracy: 0.9733 - val_loss: 3.1200 - val_accuracy: 0.5582\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0723 - accuracy: 0.9751 - val_loss: 3.1502 - val_accuracy: 0.5593\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 3.1567 - val_accuracy: 0.5583\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0772 - accuracy: 0.9749 - val_loss: 3.2336 - val_accuracy: 0.5613\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 3.2428 - val_accuracy: 0.5610\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 2.9357 - val_accuracy: 0.5596\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.0709 - accuracy: 0.9754 - val_loss: 3.1099 - val_accuracy: 0.5577\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 3.0640 - val_accuracy: 0.5559\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMLResNet\n",
    "Generate RML Residual Network  as defined in O'Shea et Al., <i> Over-the-Air Deep Learning Based Radio Signal Classification</i>,  2018. \n",
    "The implementation is an adaptation of https://github.com/liuzhejun/ResNet-for-Radio-Recognition/blob/master/ResNet_Model.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 2, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ReStk1_conv1 (Conv2D)           (None, 128, 2, 32)   64          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ReStk1_conv2 (Conv2D)           (None, 128, 2, 32)   6176        ReStk1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk1_conv3 (Conv2D)           (None, 128, 2, 32)   6176        ReStk1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 2, 32)   0           ReStk1_conv3[0][0]               \n",
      "                                                                 ReStk1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 2, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "ReStk1_conv4 (Conv2D)           (None, 128, 2, 32)   6176        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ReStk1_conv5 (Conv2D)           (None, 128, 2, 32)   6176        ReStk1_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 2, 32)   0           ReStk1_conv5[0][0]               \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 2, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 1, 32)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk2_conv1 (Conv2D)           (None, 64, 1, 32)    1056        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ReStk2_conv2 (Conv2D)           (None, 64, 1, 32)    6176        ReStk2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk2_conv3 (Conv2D)           (None, 64, 1, 32)    6176        ReStk2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 1, 32)    0           ReStk2_conv3[0][0]               \n",
      "                                                                 ReStk2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 1, 32)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ReStk2_conv4 (Conv2D)           (None, 64, 1, 32)    6176        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk2_conv5 (Conv2D)           (None, 64, 1, 32)    6176        ReStk2_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 1, 32)    0           ReStk2_conv5[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 1, 32)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 1, 32)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk3_conv1 (Conv2D)           (None, 32, 1, 32)    1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ReStk3_conv2 (Conv2D)           (None, 32, 1, 32)    6176        ReStk3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk3_conv3 (Conv2D)           (None, 32, 1, 32)    6176        ReStk3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 1, 32)    0           ReStk3_conv3[0][0]               \n",
      "                                                                 ReStk3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 1, 32)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ReStk3_conv4 (Conv2D)           (None, 32, 1, 32)    6176        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk3_conv5 (Conv2D)           (None, 32, 1, 32)    6176        ReStk3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 1, 32)    0           ReStk3_conv5[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 1, 32)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 1, 32)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk4_conv1 (Conv2D)           (None, 16, 1, 32)    1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ReStk4_conv2 (Conv2D)           (None, 16, 1, 32)    6176        ReStk4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk4_conv3 (Conv2D)           (None, 16, 1, 32)    6176        ReStk4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 1, 32)    0           ReStk4_conv3[0][0]               \n",
      "                                                                 ReStk4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 1, 32)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ReStk4_conv4 (Conv2D)           (None, 16, 1, 32)    6176        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk4_conv5 (Conv2D)           (None, 16, 1, 32)    6176        ReStk4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 1, 32)    0           ReStk4_conv5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 1, 32)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 1, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk5_conv1 (Conv2D)           (None, 8, 1, 32)     1056        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ReStk5_conv2 (Conv2D)           (None, 8, 1, 32)     6176        ReStk5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk5_conv3 (Conv2D)           (None, 8, 1, 32)     6176        ReStk5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 1, 32)     0           ReStk5_conv3[0][0]               \n",
      "                                                                 ReStk5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 1, 32)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ReStk5_conv4 (Conv2D)           (None, 8, 1, 32)     6176        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk5_conv5 (Conv2D)           (None, 8, 1, 32)     6176        ReStk5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 1, 32)     0           ReStk5_conv5[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 1, 32)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 1, 32)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk6_conv1 (Conv2D)           (None, 4, 1, 32)     1056        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ReStk6_conv2 (Conv2D)           (None, 4, 1, 32)     6176        ReStk6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ReStk6_conv3 (Conv2D)           (None, 4, 1, 32)     6176        ReStk6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 1, 32)     0           ReStk6_conv3[0][0]               \n",
      "                                                                 ReStk6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 1, 32)     0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ReStk6_conv4 (Conv2D)           (None, 4, 1, 32)     6176        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ReStk6_conv5 (Conv2D)           (None, 4, 1, 32)     6176        ReStk6_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 1, 32)     0           ReStk6_conv5[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 1, 32)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 1, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 128)          8320        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout (AlphaDropout)    (None, 128)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          16512       alpha_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropout)  (None, 128)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 7)            903         alpha_dropout_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 179,303\n",
      "Trainable params: 179,303\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "name_network = \"RMLResNet\"\n",
    "\n",
    "model = getattr(neural_nets_keras,'get_{}'.format(name_network))(input_shp,output_shp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 183s 549ms/step - loss: 2.1894 - accuracy: 0.1565 - val_loss: 1.6906 - val_accuracy: 0.2629\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 1.6452 - accuracy: 0.2821 - val_loss: 1.6101 - val_accuracy: 0.3174\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 1.4873 - accuracy: 0.3566 - val_loss: 1.1553 - val_accuracy: 0.4655\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 1.1475 - accuracy: 0.4625 - val_loss: 1.2031 - val_accuracy: 0.4817\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 1.0980 - accuracy: 0.4856 - val_loss: 1.1522 - val_accuracy: 0.5037\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 1.0051 - accuracy: 0.5254 - val_loss: 1.0528 - val_accuracy: 0.5221\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.9841 - accuracy: 0.5305 - val_loss: 1.0153 - val_accuracy: 0.5385\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.9446 - accuracy: 0.5470 - val_loss: 0.9774 - val_accuracy: 0.5549\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.9236 - accuracy: 0.5561 - val_loss: 0.9375 - val_accuracy: 0.5587\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.9132 - accuracy: 0.5626 - val_loss: 0.9514 - val_accuracy: 0.5594\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.8922 - accuracy: 0.5668 - val_loss: 0.9354 - val_accuracy: 0.5688\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8723 - accuracy: 0.5789 - val_loss: 0.9232 - val_accuracy: 0.5676\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.8714 - accuracy: 0.5721 - val_loss: 1.0066 - val_accuracy: 0.5546\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.8729 - accuracy: 0.5794 - val_loss: 0.9345 - val_accuracy: 0.5644\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.8613 - accuracy: 0.5800 - val_loss: 0.9368 - val_accuracy: 0.5653\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.8538 - accuracy: 0.5811 - val_loss: 0.9452 - val_accuracy: 0.5757\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8529 - accuracy: 0.5860 - val_loss: 0.9228 - val_accuracy: 0.5732\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8681 - accuracy: 0.5764 - val_loss: 0.9195 - val_accuracy: 0.5704\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.8500 - accuracy: 0.5887 - val_loss: 0.9193 - val_accuracy: 0.5784\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.8375 - accuracy: 0.5900 - val_loss: 0.9686 - val_accuracy: 0.5790\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.8356 - accuracy: 0.5958 - val_loss: 0.9282 - val_accuracy: 0.5831\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.8331 - accuracy: 0.5973 - val_loss: 0.9362 - val_accuracy: 0.5842\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.8180 - accuracy: 0.6022 - val_loss: 0.9017 - val_accuracy: 0.5821\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.8143 - accuracy: 0.6061 - val_loss: 0.9108 - val_accuracy: 0.5942\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8051 - accuracy: 0.6121 - val_loss: 0.9481 - val_accuracy: 0.5910\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.8099 - accuracy: 0.6157 - val_loss: 1.1749 - val_accuracy: 0.5196\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.9187 - accuracy: 0.5736 - val_loss: 0.9519 - val_accuracy: 0.5945\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.8051 - accuracy: 0.6223 - val_loss: 0.9814 - val_accuracy: 0.5920\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.8098 - accuracy: 0.6195 - val_loss: 0.9155 - val_accuracy: 0.6100\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7936 - accuracy: 0.6325 - val_loss: 0.9679 - val_accuracy: 0.6222\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 7s 38ms/step - loss: 0.7796 - accuracy: 0.6375 - val_loss: 1.0379 - val_accuracy: 0.5989\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 7s 38ms/step - loss: 0.7752 - accuracy: 0.6431 - val_loss: 0.9007 - val_accuracy: 0.6268\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.7560 - accuracy: 0.6523 - val_loss: 0.9336 - val_accuracy: 0.6242\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7602 - accuracy: 0.6523 - val_loss: 0.9602 - val_accuracy: 0.6230\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7479 - accuracy: 0.6572 - val_loss: 0.9834 - val_accuracy: 0.6293\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7431 - accuracy: 0.6566 - val_loss: 0.9109 - val_accuracy: 0.6204\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7308 - accuracy: 0.6661 - val_loss: 0.9992 - val_accuracy: 0.6373\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7286 - accuracy: 0.6666 - val_loss: 0.9659 - val_accuracy: 0.6327\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7254 - accuracy: 0.6701 - val_loss: 0.9549 - val_accuracy: 0.6363\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7261 - accuracy: 0.6699 - val_loss: 0.9055 - val_accuracy: 0.6390\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.7035 - accuracy: 0.6775 - val_loss: 0.9448 - val_accuracy: 0.6412\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.7022 - accuracy: 0.6779 - val_loss: 0.9576 - val_accuracy: 0.6377\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6863 - accuracy: 0.6872 - val_loss: 1.0333 - val_accuracy: 0.6352\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6944 - accuracy: 0.6824 - val_loss: 0.9791 - val_accuracy: 0.6421\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6812 - accuracy: 0.6888 - val_loss: 1.0150 - val_accuracy: 0.6410\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.6799 - accuracy: 0.6914 - val_loss: 0.9493 - val_accuracy: 0.6467\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.6743 - accuracy: 0.6937 - val_loss: 0.9973 - val_accuracy: 0.6506\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.6629 - accuracy: 0.6982 - val_loss: 1.0512 - val_accuracy: 0.6564\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.6629 - accuracy: 0.6972 - val_loss: 0.9945 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6530 - accuracy: 0.7052 - val_loss: 1.0860 - val_accuracy: 0.6508\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6520 - accuracy: 0.7043 - val_loss: 1.0779 - val_accuracy: 0.6451\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.6448 - accuracy: 0.7083 - val_loss: 1.0745 - val_accuracy: 0.6589\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6610 - accuracy: 0.7055 - val_loss: 1.1054 - val_accuracy: 0.6577\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6317 - accuracy: 0.7152 - val_loss: 1.0157 - val_accuracy: 0.6420\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.6444 - accuracy: 0.7094 - val_loss: 1.1237 - val_accuracy: 0.6548\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6163 - accuracy: 0.7217 - val_loss: 1.2407 - val_accuracy: 0.6541\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6214 - accuracy: 0.7191 - val_loss: 1.1340 - val_accuracy: 0.6509\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.6175 - accuracy: 0.7226 - val_loss: 1.1374 - val_accuracy: 0.6542\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6136 - accuracy: 0.7236 - val_loss: 1.0693 - val_accuracy: 0.6615\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.6058 - accuracy: 0.7284 - val_loss: 1.1715 - val_accuracy: 0.6578\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6031 - accuracy: 0.7301 - val_loss: 0.9690 - val_accuracy: 0.6573\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.6073 - accuracy: 0.7280 - val_loss: 1.0948 - val_accuracy: 0.6503\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.6058 - accuracy: 0.7310 - val_loss: 1.1723 - val_accuracy: 0.6616\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5849 - accuracy: 0.7378 - val_loss: 1.2103 - val_accuracy: 0.6614\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5830 - accuracy: 0.7386 - val_loss: 1.2372 - val_accuracy: 0.6637\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5902 - accuracy: 0.7368 - val_loss: 1.1828 - val_accuracy: 0.6597\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5899 - accuracy: 0.7363 - val_loss: 1.1249 - val_accuracy: 0.6599\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5754 - accuracy: 0.7446 - val_loss: 1.2324 - val_accuracy: 0.6655\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.5648 - accuracy: 0.7490 - val_loss: 1.3738 - val_accuracy: 0.6585\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5766 - accuracy: 0.7435 - val_loss: 1.1679 - val_accuracy: 0.6631\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5685 - accuracy: 0.7494 - val_loss: 1.3252 - val_accuracy: 0.6616\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5566 - accuracy: 0.7544 - val_loss: 1.1709 - val_accuracy: 0.6630\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5646 - accuracy: 0.7516 - val_loss: 1.3088 - val_accuracy: 0.6609\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5683 - accuracy: 0.7506 - val_loss: 1.3033 - val_accuracy: 0.6642\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5506 - accuracy: 0.7571 - val_loss: 1.2573 - val_accuracy: 0.6660\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5476 - accuracy: 0.7597 - val_loss: 1.2693 - val_accuracy: 0.6635\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5498 - accuracy: 0.7574 - val_loss: 1.1834 - val_accuracy: 0.6659\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5549 - accuracy: 0.7550 - val_loss: 1.3532 - val_accuracy: 0.6629\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.5429 - accuracy: 0.7635 - val_loss: 1.3224 - val_accuracy: 0.6666\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5423 - accuracy: 0.7620 - val_loss: 1.3312 - val_accuracy: 0.6645\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5346 - accuracy: 0.7674 - val_loss: 1.5758 - val_accuracy: 0.6694\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.5324 - accuracy: 0.7662 - val_loss: 1.4702 - val_accuracy: 0.6609\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5458 - accuracy: 0.7613 - val_loss: 1.3891 - val_accuracy: 0.6662\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5293 - accuracy: 0.7686 - val_loss: 1.3662 - val_accuracy: 0.6623\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.5390 - accuracy: 0.7662 - val_loss: 1.2592 - val_accuracy: 0.6625\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.5385 - accuracy: 0.7651 - val_loss: 1.3538 - val_accuracy: 0.6551\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5243 - accuracy: 0.7695 - val_loss: 1.4248 - val_accuracy: 0.6638\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5178 - accuracy: 0.7757 - val_loss: 1.5098 - val_accuracy: 0.6610\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.5282 - accuracy: 0.7710 - val_loss: 1.4394 - val_accuracy: 0.6671\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.5067 - accuracy: 0.7793 - val_loss: 1.4680 - val_accuracy: 0.6640\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5123 - accuracy: 0.7793 - val_loss: 1.3729 - val_accuracy: 0.6659\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5071 - accuracy: 0.7800 - val_loss: 1.4013 - val_accuracy: 0.6634\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.5133 - accuracy: 0.7771 - val_loss: 1.5737 - val_accuracy: 0.6637\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5151 - accuracy: 0.7796 - val_loss: 1.3513 - val_accuracy: 0.6631\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5039 - accuracy: 0.7820 - val_loss: 1.5256 - val_accuracy: 0.6657\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4992 - accuracy: 0.7849 - val_loss: 1.3737 - val_accuracy: 0.6679\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4962 - accuracy: 0.7832 - val_loss: 1.5331 - val_accuracy: 0.6675\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4907 - accuracy: 0.7867 - val_loss: 1.4365 - val_accuracy: 0.6690\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4850 - accuracy: 0.7896 - val_loss: 1.4614 - val_accuracy: 0.6715\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4821 - accuracy: 0.7910 - val_loss: 1.7918 - val_accuracy: 0.6575\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4946 - accuracy: 0.7888 - val_loss: 1.4789 - val_accuracy: 0.6633\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.5007 - accuracy: 0.7855 - val_loss: 1.4195 - val_accuracy: 0.6648\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4922 - accuracy: 0.7884 - val_loss: 1.5719 - val_accuracy: 0.6643\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4804 - accuracy: 0.7929 - val_loss: 1.6436 - val_accuracy: 0.6609\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4854 - accuracy: 0.7931 - val_loss: 1.6668 - val_accuracy: 0.6635\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4869 - accuracy: 0.7916 - val_loss: 1.6020 - val_accuracy: 0.6680\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4803 - accuracy: 0.7953 - val_loss: 1.5203 - val_accuracy: 0.6617\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4791 - accuracy: 0.7947 - val_loss: 1.5888 - val_accuracy: 0.6619\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4676 - accuracy: 0.8010 - val_loss: 1.6811 - val_accuracy: 0.6672\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4828 - accuracy: 0.7952 - val_loss: 1.6308 - val_accuracy: 0.6686\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4705 - accuracy: 0.8002 - val_loss: 1.5296 - val_accuracy: 0.6653\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4724 - accuracy: 0.7981 - val_loss: 1.7693 - val_accuracy: 0.6643\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4738 - accuracy: 0.8001 - val_loss: 1.5417 - val_accuracy: 0.6670\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.4529 - accuracy: 0.8074 - val_loss: 1.7251 - val_accuracy: 0.6636\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.4569 - accuracy: 0.8069 - val_loss: 1.6776 - val_accuracy: 0.6685\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4624 - accuracy: 0.8048 - val_loss: 1.7361 - val_accuracy: 0.6698\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4579 - accuracy: 0.8077 - val_loss: 1.7970 - val_accuracy: 0.6640\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.4698 - accuracy: 0.8018 - val_loss: 1.4892 - val_accuracy: 0.6665\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4551 - accuracy: 0.8067 - val_loss: 1.7375 - val_accuracy: 0.6674\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4540 - accuracy: 0.8085 - val_loss: 1.6787 - val_accuracy: 0.6629\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4519 - accuracy: 0.8085 - val_loss: 1.8365 - val_accuracy: 0.6673\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4506 - accuracy: 0.8086 - val_loss: 1.6459 - val_accuracy: 0.6677\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.4545 - accuracy: 0.8087 - val_loss: 1.6960 - val_accuracy: 0.6673\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4414 - accuracy: 0.8143 - val_loss: 1.7186 - val_accuracy: 0.6650\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4458 - accuracy: 0.8105 - val_loss: 1.7183 - val_accuracy: 0.6645\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4499 - accuracy: 0.8107 - val_loss: 1.9253 - val_accuracy: 0.6493\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4639 - accuracy: 0.8054 - val_loss: 1.8762 - val_accuracy: 0.6637\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4510 - accuracy: 0.8105 - val_loss: 1.7699 - val_accuracy: 0.6643\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4431 - accuracy: 0.8148 - val_loss: 1.5908 - val_accuracy: 0.6662\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4343 - accuracy: 0.8182 - val_loss: 1.7411 - val_accuracy: 0.6698\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4332 - accuracy: 0.8195 - val_loss: 1.9113 - val_accuracy: 0.6661\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4372 - accuracy: 0.8155 - val_loss: 1.4940 - val_accuracy: 0.6652\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4444 - accuracy: 0.8126 - val_loss: 2.2258 - val_accuracy: 0.6713\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4390 - accuracy: 0.8164 - val_loss: 1.8902 - val_accuracy: 0.6687\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4348 - accuracy: 0.8189 - val_loss: 1.6353 - val_accuracy: 0.6673\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4309 - accuracy: 0.8199 - val_loss: 1.6837 - val_accuracy: 0.6644\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4249 - accuracy: 0.8221 - val_loss: 1.8975 - val_accuracy: 0.6656\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4237 - accuracy: 0.8233 - val_loss: 1.7159 - val_accuracy: 0.6618\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.4308 - accuracy: 0.8205 - val_loss: 2.0033 - val_accuracy: 0.6697\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4205 - accuracy: 0.8241 - val_loss: 2.0029 - val_accuracy: 0.6619\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.4225 - accuracy: 0.8244 - val_loss: 2.0812 - val_accuracy: 0.6614\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4319 - accuracy: 0.8193 - val_loss: 1.6601 - val_accuracy: 0.6691\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.4161 - accuracy: 0.8266 - val_loss: 1.8858 - val_accuracy: 0.6687\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.4187 - accuracy: 0.8253 - val_loss: 1.7901 - val_accuracy: 0.6573\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.4294 - accuracy: 0.8237 - val_loss: 1.7238 - val_accuracy: 0.6622\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.4309 - accuracy: 0.8200 - val_loss: 1.9838 - val_accuracy: 0.6683\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.4152 - accuracy: 0.8275 - val_loss: 1.9364 - val_accuracy: 0.6637\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4041 - accuracy: 0.8314 - val_loss: 1.9687 - val_accuracy: 0.6679\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4155 - accuracy: 0.8272 - val_loss: 1.8024 - val_accuracy: 0.6663\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4007 - accuracy: 0.8347 - val_loss: 2.0263 - val_accuracy: 0.6659\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.4245 - accuracy: 0.8244 - val_loss: 1.8709 - val_accuracy: 0.6644\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4143 - accuracy: 0.8281 - val_loss: 2.1886 - val_accuracy: 0.6663\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4004 - accuracy: 0.8346 - val_loss: 1.9319 - val_accuracy: 0.6616\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4167 - accuracy: 0.8271 - val_loss: 1.8967 - val_accuracy: 0.6662\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4050 - accuracy: 0.8325 - val_loss: 2.1833 - val_accuracy: 0.6676\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.3977 - accuracy: 0.8386 - val_loss: 1.9436 - val_accuracy: 0.6657\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.3995 - accuracy: 0.8327 - val_loss: 1.9780 - val_accuracy: 0.6680\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.3996 - accuracy: 0.8361 - val_loss: 1.9809 - val_accuracy: 0.6635\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.3927 - accuracy: 0.8374 - val_loss: 2.0063 - val_accuracy: 0.6646\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.3969 - accuracy: 0.8387 - val_loss: 1.9377 - val_accuracy: 0.6670\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.3895 - accuracy: 0.8361 - val_loss: 2.0316 - val_accuracy: 0.6653\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.4006 - accuracy: 0.8346 - val_loss: 2.0824 - val_accuracy: 0.6651\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.4027 - accuracy: 0.8339 - val_loss: 1.8764 - val_accuracy: 0.6641\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.3955 - accuracy: 0.8383 - val_loss: 2.0148 - val_accuracy: 0.6690\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.3852 - accuracy: 0.8417 - val_loss: 2.0447 - val_accuracy: 0.6644\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 8s 46ms/step - loss: 0.3939 - accuracy: 0.8375 - val_loss: 1.9497 - val_accuracy: 0.6632\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.3996 - accuracy: 0.8346 - val_loss: 2.0795 - val_accuracy: 0.6633\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3989 - accuracy: 0.8348 - val_loss: 2.0221 - val_accuracy: 0.6675\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3880 - accuracy: 0.8407 - val_loss: 2.0919 - val_accuracy: 0.6656\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3809 - accuracy: 0.8425 - val_loss: 2.2647 - val_accuracy: 0.6686\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3771 - accuracy: 0.8447 - val_loss: 2.0242 - val_accuracy: 0.6668\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3919 - accuracy: 0.8385 - val_loss: 2.0867 - val_accuracy: 0.6670\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3868 - accuracy: 0.8403 - val_loss: 1.9503 - val_accuracy: 0.6670\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3803 - accuracy: 0.8433 - val_loss: 2.0954 - val_accuracy: 0.6683\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3753 - accuracy: 0.8433 - val_loss: 2.0872 - val_accuracy: 0.6661\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3848 - accuracy: 0.8418 - val_loss: 2.0648 - val_accuracy: 0.6691\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.3856 - accuracy: 0.8407 - val_loss: 2.2811 - val_accuracy: 0.6651\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3802 - accuracy: 0.8427 - val_loss: 2.0605 - val_accuracy: 0.6664\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3787 - accuracy: 0.8442 - val_loss: 1.9304 - val_accuracy: 0.6674\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3876 - accuracy: 0.8420 - val_loss: 2.2397 - val_accuracy: 0.6651\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3709 - accuracy: 0.8463 - val_loss: 2.0526 - val_accuracy: 0.6704\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3871 - accuracy: 0.8406 - val_loss: 2.0390 - val_accuracy: 0.6703\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3726 - accuracy: 0.8463 - val_loss: 2.1558 - val_accuracy: 0.6690\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 7s 42ms/step - loss: 0.3784 - accuracy: 0.8442 - val_loss: 2.1522 - val_accuracy: 0.6637\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3785 - accuracy: 0.8449 - val_loss: 2.2921 - val_accuracy: 0.6679\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3769 - accuracy: 0.8442 - val_loss: 2.3527 - val_accuracy: 0.6654\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3773 - accuracy: 0.8453 - val_loss: 2.2333 - val_accuracy: 0.6695\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.3710 - accuracy: 0.8496 - val_loss: 2.1617 - val_accuracy: 0.6641\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 0.3861 - accuracy: 0.8444 - val_loss: 2.2326 - val_accuracy: 0.6663\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3713 - accuracy: 0.8470 - val_loss: 2.2510 - val_accuracy: 0.6686\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3828 - accuracy: 0.8430 - val_loss: 1.9913 - val_accuracy: 0.6665\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 7s 38ms/step - loss: 0.3696 - accuracy: 0.8495 - val_loss: 2.2371 - val_accuracy: 0.6657\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3702 - accuracy: 0.8501 - val_loss: 2.0074 - val_accuracy: 0.6662\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 7s 39ms/step - loss: 0.3589 - accuracy: 0.8535 - val_loss: 2.2931 - val_accuracy: 0.6693\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 7s 41ms/step - loss: 0.3575 - accuracy: 0.8528 - val_loss: 2.1698 - val_accuracy: 0.6662\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 7s 43ms/step - loss: 0.3585 - accuracy: 0.8538 - val_loss: 2.3011 - val_accuracy: 0.6646\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 8s 45ms/step - loss: 0.3639 - accuracy: 0.8507 - val_loss: 2.1310 - val_accuracy: 0.6702\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.3705 - accuracy: 0.8497 - val_loss: 1.9492 - val_accuracy: 0.6675\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 7s 44ms/step - loss: 0.3662 - accuracy: 0.8505 - val_loss: 2.2281 - val_accuracy: 0.6672\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 8s 44ms/step - loss: 0.3728 - accuracy: 0.8483 - val_loss: 2.3240 - val_accuracy: 0.6645\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_model(model, name_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_name_to_legend = {\n",
    "    'RMLConvNet':'RML-ConvNet',\n",
    "    'RMLCNNVGG':'RML-CNN/VGG',\n",
    "    'RMLResNet':'RML-ResNet',\n",
    "    'LModCNN':'Mod-LCNN (ours)',\n",
    "    'LModCNNResNetRelu':'Mod-LRCNN (ours)',\n",
    "}\n",
    "\n",
    "networks_to_plot = ['RMLConvNet','RMLCNNVGG','RMLResNet','LModCNN','LModCNNResNetRelu' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training trajectories\n",
    "\n",
    "Plots the evolution of error through learning epochs both for train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for name_network in networks_to_plot:\n",
    "\n",
    "    data = np.loadtxt(join(log_path,'history-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)))\n",
    "\n",
    "    p = plt.plot(data[:,0], 1.-data[:,1],\n",
    "        label=from_name_to_legend[name_network],linewidth=2)\n",
    "    plt.plot(data[:,0], 1.-data[:,2],':',\n",
    "        linewidth=2,color=p[0].get_color(),alpha=0.8)\n",
    "\n",
    "plt.plot(data[:,0] ,1.-1./output_shp*np.ones_like(data[:,0]),\n",
    "    '--',label='Random classifier',linewidth=2,color='black')\n",
    "\n",
    "plt.legend(ncol=2,loc=1)\n",
    "plt.grid()\n",
    "plt.ylabel('Error = 1-Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f'Data set: {dataset_name}, Samples per signal: {signal_duration}')\n",
    "plt.ylim([0.,1.])\n",
    "plt.xlim([1,nb_epoch])\n",
    "plt.savefig(join(log_path,'network_comparison_{}-trained{}.pdf'.format(dataset_name,signal_duration)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solid curves are for the test set and dotted curves for the training set\n",
    "\n",
    "Lower is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print final performances\n",
    "\n",
    "Displays test accuracy for different algorithmes and train/test computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(log_path,'perfs-{}-{}-trained{}.txt'.format(dataset_name,'all',signal_duration)), 'w')\n",
    "\n",
    "f.write(f'#Performance evaluations, Data set: {dataset_name}, Samples per signal: {signal_duration}\\n')\n",
    "    \n",
    "f.write(f\"#{'':20s}{'Loss':15s}{'Accuracy':15s}{'Training time':20s}{'Inference time':20s}{'# Parameters':15s}\\n\")\n",
    "f.write(f\"#{'':20s}{'':15s}{'':15s}{'(s/epoch)':20s}{'(ms/signal)':20s}\\n\")\n",
    "f.write(f\"#{'-'*110}\\n\")\n",
    "\n",
    "for name_network in networks_to_plot:\n",
    "    \n",
    "    training_time_vec=  np.loadtxt(join(log_path,'history_time-{}-{}-trained{}.txt'.format(dataset_name,name_network,signal_duration)))\n",
    "    training_time = training_time_vec[:,1].mean()\n",
    "    \n",
    "    model = load_model(join(log_path,'model-{}-{}-trained{}.h5'.format(dataset_name,name_network,signal_duration)))\n",
    "    mod_size = model.count_params()\n",
    "   \n",
    "    t = time.time()\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test,\n",
    "        verbose=False,batch_size=batch_size)\n",
    "    t_proc= 1000.0*(time.time()-t)/X_test.shape[0] #ms\n",
    "\n",
    "    f.write(f\"{from_name_to_legend[name_network]:20s}{test_loss:2.3f}{'':10s}{test_acc:2.3f}{'':10s}{training_time:>4.1f}{'':17s}{t_proc:>4.2}{'':16s}{mod_size:>10,d}\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Performance evaluations, Data set: AugMod, Samples per signal: 128\n",
      "#                    Loss           Accuracy       Training time       Inference time      # Parameters   \n",
      "#                                                  (s/epoch)           (ms/signal)         \n",
      "#--------------------------------------------------------------------------------------------------------------\n",
      "RML-ConvNet         0.902          0.609           7.4                 0.019                 2,829,399\n",
      "RML-CNN/VGG         3.064          0.556           3.8                 0.015                   199,111\n",
      "RML-ResNet          2.324          0.665           8.2                 0.024                   179,303\n",
      "Mod-LCNN (ours)     0.659          0.721           3.8                 0.012                    37,487\n",
      "Mod-LRCNN (ours)    0.885          0.740           7.7                 0.025                    97,663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(join(log_path,'perfs-{}-{}-trained{}.txt'.format(dataset_name,'all',signal_duration)), 'r')\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
